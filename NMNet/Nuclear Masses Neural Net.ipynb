{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclear Mass Neural Net\n",
    "\n",
    "This short tensorflow toy trains a standard neural network to output binding energy based on an input neutron and proton number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:75: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      "   Shape: (1997, 2)\n",
      "   Type: float64\n",
      "\n",
      "Training Targets:\n",
      "   Shape: (1997,)\n",
      "   Type: float64\n",
      "\n",
      "Test Features:\n",
      "   Shape: (500, 2)\n",
      "   Type: float64\n",
      "\n",
      "Test Targets:\n",
      "   Shape: (500,)\n",
      "   Type: float64\n",
      "\n",
      "Train on 1597 samples, validate on 400 samples\n",
      "Epoch 1/5000\n",
      "1597/1597 [==============================] - 2s 2ms/sample - loss: 61.9673 - R2: -349.5199 - val_loss: 58.5748 - val_R2: -303.8964\n",
      "Epoch 2/5000\n",
      "1597/1597 [==============================] - 0s 302us/sample - loss: 50.1203 - R2: -273.6432 - val_loss: 38.7200 - val_R2: -214.1431\n",
      "Epoch 3/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 22.6624 - R2: -120.1408 - val_loss: 9.7923 - val_R2: -52.1532\n",
      "Epoch 4/5000\n",
      "1597/1597 [==============================] - 0s 296us/sample - loss: 6.4928 - R2: -34.1163 - val_loss: 5.0284 - val_R2: -21.7878\n",
      "Epoch 5/5000\n",
      "1597/1597 [==============================] - 0s 281us/sample - loss: 4.2718 - R2: -17.8579 - val_loss: 3.4792 - val_R2: -14.1756\n",
      "Epoch 6/5000\n",
      "1597/1597 [==============================] - 0s 278us/sample - loss: 2.9103 - R2: -11.4094 - val_loss: 2.3334 - val_R2: -7.4196\n",
      "Epoch 7/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 1.9241 - R2: -5.9202 - val_loss: 1.4963 - val_R2: -3.9905\n",
      "Epoch 8/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 1.2426 - R2: -2.9971 - val_loss: 0.9833 - val_R2: -1.8380\n",
      "Epoch 9/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.8358 - R2: -1.2270 - val_loss: 0.6715 - val_R2: -0.5263\n",
      "Epoch 10/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.6036 - R2: -0.3498 - val_loss: 0.5149 - val_R2: -0.0166\n",
      "Epoch 11/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.4880 - R2: -0.0104 - val_loss: 0.4410 - val_R2: 0.1436\n",
      "Epoch 12/5000\n",
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.4342 - R2: 0.0936 - val_loss: 0.4050 - val_R2: 0.1192\n",
      "Epoch 13/5000\n",
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.4011 - R2: 0.1497 - val_loss: 0.3771 - val_R2: 0.2450\n",
      "Epoch 14/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.3734 - R2: 0.2167 - val_loss: 0.3550 - val_R2: 0.4119\n",
      "Epoch 15/5000\n",
      "1597/1597 [==============================] - 0s 296us/sample - loss: 0.3521 - R2: 0.3150 - val_loss: 0.3302 - val_R2: 0.3574\n",
      "Epoch 16/5000\n",
      "1597/1597 [==============================] - 0s 295us/sample - loss: 0.3357 - R2: 0.3295 - val_loss: 0.3144 - val_R2: 0.4626\n",
      "Epoch 17/5000\n",
      "1597/1597 [==============================] - 0s 283us/sample - loss: 0.3178 - R2: 0.3970 - val_loss: 0.3031 - val_R2: 0.3628\n",
      "Epoch 18/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.3060 - R2: 0.4133 - val_loss: 0.2907 - val_R2: 0.5240\n",
      "Epoch 19/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.2942 - R2: 0.4585 - val_loss: 0.2808 - val_R2: 0.2951\n",
      "Epoch 20/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.2833 - R2: 0.4297 - val_loss: 0.2669 - val_R2: 0.4605\n",
      "Epoch 21/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.2738 - R2: 0.4476 - val_loss: 0.2589 - val_R2: 0.5632\n",
      "Epoch 22/5000\n",
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.2624 - R2: 0.5193 - val_loss: 0.2489 - val_R2: 0.5045\n",
      "Epoch 23/5000\n",
      "1597/1597 [==============================] - 0s 292us/sample - loss: 0.2541 - R2: 0.5228 - val_loss: 0.2431 - val_R2: 0.5236\n",
      "Epoch 24/5000\n",
      "1597/1597 [==============================] - 0s 272us/sample - loss: 0.2484 - R2: 0.5031 - val_loss: 0.2357 - val_R2: 0.6237\n",
      "Epoch 25/5000\n",
      "1597/1597 [==============================] - 0s 304us/sample - loss: 0.2434 - R2: 0.5475 - val_loss: 0.2298 - val_R2: 0.5746\n",
      "Epoch 26/5000\n",
      "1597/1597 [==============================] - 0s 305us/sample - loss: 0.2318 - R2: 0.6171 - val_loss: 0.2212 - val_R2: 0.4983\n",
      "Epoch 27/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.2253 - R2: 0.5602 - val_loss: 0.2209 - val_R2: 0.6934\n",
      "Epoch 28/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.2225 - R2: 0.5913 - val_loss: 0.2102 - val_R2: 0.6177\n",
      "Epoch 29/5000\n",
      "1597/1597 [==============================] - 0s 292us/sample - loss: 0.2158 - R2: 0.6313 - val_loss: 0.2071 - val_R2: 0.5669\n",
      "Epoch 30/5000\n",
      "1597/1597 [==============================] - 0s 278us/sample - loss: 0.2101 - R2: 0.6293 - val_loss: 0.1981 - val_R2: 0.5818\n",
      "Epoch 31/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.2046 - R2: 0.5333 - val_loss: 0.1934 - val_R2: 0.6612\n",
      "Epoch 32/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.2023 - R2: 0.5838 - val_loss: 0.1912 - val_R2: 0.6759\n",
      "Epoch 33/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.1977 - R2: 0.6018 - val_loss: 0.1900 - val_R2: 0.7486\n",
      "Epoch 34/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.1928 - R2: 0.6725 - val_loss: 0.1816 - val_R2: 0.7094\n",
      "Epoch 35/5000\n",
      "1597/1597 [==============================] - 0s 279us/sample - loss: 0.1945 - R2: 0.5977 - val_loss: 0.1768 - val_R2: 0.7055\n",
      "Epoch 36/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.1866 - R2: 0.5879 - val_loss: 0.1702 - val_R2: 0.6354\n",
      "Epoch 37/5000\n",
      "1597/1597 [==============================] - 0s 284us/sample - loss: 0.1880 - R2: 0.6347 - val_loss: 0.1702 - val_R2: 0.6312\n",
      "Epoch 38/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.1799 - R2: 0.7116 - val_loss: 0.1684 - val_R2: 0.5842\n",
      "Epoch 39/5000\n",
      "1597/1597 [==============================] - 0s 295us/sample - loss: 0.1776 - R2: 0.6533 - val_loss: 0.1593 - val_R2: 0.7037\n",
      "Epoch 40/5000\n",
      "1597/1597 [==============================] - 0s 292us/sample - loss: 0.1754 - R2: 0.6527 - val_loss: 0.1540 - val_R2: 0.7111\n",
      "Epoch 41/5000\n",
      "1597/1597 [==============================] - 0s 292us/sample - loss: 0.1710 - R2: 0.6243 - val_loss: 0.1572 - val_R2: 0.7469\n",
      "Epoch 42/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.1701 - R2: 0.6121 - val_loss: 0.1490 - val_R2: 0.6634\n",
      "Epoch 43/5000\n",
      "1597/1597 [==============================] - 0s 296us/sample - loss: 0.1680 - R2: 0.6741 - val_loss: 0.1442 - val_R2: 0.7007\n",
      "Epoch 44/5000\n",
      "1597/1597 [==============================] - 0s 306us/sample - loss: 0.1661 - R2: 0.6667 - val_loss: 0.1431 - val_R2: 0.6153\n",
      "Epoch 45/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.1681 - R2: 0.6742 - val_loss: 0.1456 - val_R2: 0.5492\n",
      "Epoch 46/5000\n",
      "1597/1597 [==============================] - 0s 302us/sample - loss: 0.1623 - R2: 0.6520 - val_loss: 0.1446 - val_R2: 0.7232\n",
      "Epoch 47/5000\n",
      "1597/1597 [==============================] - 0s 310us/sample - loss: 0.1580 - R2: 0.6858 - val_loss: 0.1366 - val_R2: 0.7168\n",
      "Epoch 48/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.1565 - R2: 0.6667 - val_loss: 0.1304 - val_R2: 0.7676\n",
      "Epoch 49/5000\n",
      "1597/1597 [==============================] - 0s 274us/sample - loss: 0.1550 - R2: 0.6698 - val_loss: 0.1286 - val_R2: 0.6351\n",
      "Epoch 50/5000\n",
      "1597/1597 [==============================] - 0s 295us/sample - loss: 0.1539 - R2: 0.6368 - val_loss: 0.1252 - val_R2: 0.7302\n",
      "Epoch 51/5000\n",
      "1597/1597 [==============================] - 0s 310us/sample - loss: 0.1550 - R2: 0.6180 - val_loss: 0.1255 - val_R2: 0.7006\n",
      "Epoch 52/5000\n",
      "1597/1597 [==============================] - 0s 309us/sample - loss: 0.1518 - R2: 0.6906 - val_loss: 0.1229 - val_R2: 0.7569\n",
      "Epoch 53/5000\n",
      "1597/1597 [==============================] - 0s 300us/sample - loss: 0.1494 - R2: 0.6936 - val_loss: 0.1255 - val_R2: 0.7540\n",
      "Epoch 54/5000\n",
      "1597/1597 [==============================] - 0s 297us/sample - loss: 0.1482 - R2: 0.6380 - val_loss: 0.1304 - val_R2: 0.8330\n",
      "Epoch 55/5000\n",
      "1597/1597 [==============================] - 0s 281us/sample - loss: 0.1494 - R2: 0.6574 - val_loss: 0.1212 - val_R2: 0.7973\n",
      "Epoch 56/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.1447 - R2: 0.6635 - val_loss: 0.1154 - val_R2: 0.8005\n",
      "Epoch 57/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.1426 - R2: 0.7052 - val_loss: 0.1100 - val_R2: 0.7469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/5000\n",
      "1597/1597 [==============================] - 0s 282us/sample - loss: 0.1428 - R2: 0.6897 - val_loss: 0.1102 - val_R2: 0.7909\n",
      "Epoch 59/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.1412 - R2: 0.6920 - val_loss: 0.1096 - val_R2: 0.7749\n",
      "Epoch 60/5000\n",
      "1597/1597 [==============================] - 0s 281us/sample - loss: 0.1429 - R2: 0.6651 - val_loss: 0.1102 - val_R2: 0.7642\n",
      "Epoch 61/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.1412 - R2: 0.6917 - val_loss: 0.1045 - val_R2: 0.7807\n",
      "Epoch 62/5000\n",
      "1597/1597 [==============================] - 0s 304us/sample - loss: 0.1335 - R2: 0.7161 - val_loss: 0.1053 - val_R2: 0.6614\n",
      "Epoch 63/5000\n",
      "1597/1597 [==============================] - 0s 282us/sample - loss: 0.1409 - R2: 0.6673 - val_loss: 0.1055 - val_R2: 0.7560\n",
      "Epoch 64/5000\n",
      "1597/1597 [==============================] - 0s 268us/sample - loss: 0.1386 - R2: 0.6728 - val_loss: 0.1020 - val_R2: 0.7347\n",
      "Epoch 65/5000\n",
      "1597/1597 [==============================] - 0s 270us/sample - loss: 0.1352 - R2: 0.6967 - val_loss: 0.1023 - val_R2: 0.7767\n",
      "Epoch 66/5000\n",
      "1597/1597 [==============================] - 0s 275us/sample - loss: 0.1331 - R2: 0.7126 - val_loss: 0.1056 - val_R2: 0.8144\n",
      "Epoch 67/5000\n",
      "1597/1597 [==============================] - 0s 282us/sample - loss: 0.1333 - R2: 0.7112 - val_loss: 0.1040 - val_R2: 0.8376\n",
      "Epoch 68/5000\n",
      "1597/1597 [==============================] - 0s 302us/sample - loss: 0.1331 - R2: 0.6953 - val_loss: 0.0938 - val_R2: 0.7683\n",
      "Epoch 69/5000\n",
      "1597/1597 [==============================] - 0s 304us/sample - loss: 0.1298 - R2: 0.6925 - val_loss: 0.0931 - val_R2: 0.7986\n",
      "Epoch 70/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.1307 - R2: 0.6956 - val_loss: 0.0971 - val_R2: 0.8583\n",
      "Epoch 71/5000\n",
      "1597/1597 [==============================] - 1s 313us/sample - loss: 0.1274 - R2: 0.7409 - val_loss: 0.0902 - val_R2: 0.7994\n",
      "Epoch 72/5000\n",
      "1597/1597 [==============================] - 0s 267us/sample - loss: 0.1284 - R2: 0.7467 - val_loss: 0.0855 - val_R2: 0.8186\n",
      "Epoch 73/5000\n",
      "1597/1597 [==============================] - 0s 271us/sample - loss: 0.1361 - R2: 0.6716 - val_loss: 0.0941 - val_R2: 0.8278\n",
      "Epoch 74/5000\n",
      "1597/1597 [==============================] - 0s 271us/sample - loss: 0.1253 - R2: 0.7190 - val_loss: 0.0903 - val_R2: 0.8041\n",
      "Epoch 75/5000\n",
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.1255 - R2: 0.7097 - val_loss: 0.0878 - val_R2: 0.7392\n",
      "Epoch 76/5000\n",
      "1597/1597 [==============================] - 0s 274us/sample - loss: 0.1290 - R2: 0.6995 - val_loss: 0.0828 - val_R2: 0.8297\n",
      "Epoch 77/5000\n",
      "1597/1597 [==============================] - 0s 282us/sample - loss: 0.1273 - R2: 0.7052 - val_loss: 0.0832 - val_R2: 0.8008\n",
      "Epoch 78/5000\n",
      "1597/1597 [==============================] - 0s 276us/sample - loss: 0.1224 - R2: 0.7151 - val_loss: 0.0806 - val_R2: 0.8440\n",
      "Epoch 79/5000\n",
      "1597/1597 [==============================] - 0s 301us/sample - loss: 0.1242 - R2: 0.7269 - val_loss: 0.0863 - val_R2: 0.8132\n",
      "Epoch 80/5000\n",
      "1597/1597 [==============================] - 0s 304us/sample - loss: 0.1215 - R2: 0.7395 - val_loss: 0.0802 - val_R2: 0.8328\n",
      "Epoch 81/5000\n",
      "1597/1597 [==============================] - 0s 284us/sample - loss: 0.1276 - R2: 0.6794 - val_loss: 0.0812 - val_R2: 0.8644\n",
      "Epoch 82/5000\n",
      "1597/1597 [==============================] - 0s 278us/sample - loss: 0.1160 - R2: 0.7226 - val_loss: 0.0819 - val_R2: 0.7578\n",
      "Epoch 83/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.1251 - R2: 0.6863 - val_loss: 0.0797 - val_R2: 0.8395\n",
      "Epoch 84/5000\n",
      "1597/1597 [==============================] - 0s 281us/sample - loss: 0.1234 - R2: 0.7112 - val_loss: 0.0789 - val_R2: 0.8170\n",
      "Epoch 85/5000\n",
      "1597/1597 [==============================] - 0s 280us/sample - loss: 0.1192 - R2: 0.7227 - val_loss: 0.0761 - val_R2: 0.8354\n",
      "Epoch 86/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.1158 - R2: 0.7340 - val_loss: 0.0930 - val_R2: 0.8673\n",
      "Epoch 87/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.1204 - R2: 0.7221 - val_loss: 0.0801 - val_R2: 0.8359\n",
      "Epoch 88/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.1262 - R2: 0.7008 - val_loss: 0.0767 - val_R2: 0.8444\n",
      "Epoch 89/5000\n",
      "1597/1597 [==============================] - 0s 295us/sample - loss: 0.1163 - R2: 0.7459 - val_loss: 0.0747 - val_R2: 0.8615\n",
      "Epoch 90/5000\n",
      "1597/1597 [==============================] - 0s 282us/sample - loss: 0.1196 - R2: 0.6868 - val_loss: 0.0724 - val_R2: 0.8212\n",
      "Epoch 91/5000\n",
      "1597/1597 [==============================] - 0s 284us/sample - loss: 0.1162 - R2: 0.7269 - val_loss: 0.0732 - val_R2: 0.8234\n",
      "Epoch 92/5000\n",
      "1597/1597 [==============================] - 0s 282us/sample - loss: 0.1132 - R2: 0.7379 - val_loss: 0.0801 - val_R2: 0.8587\n",
      "Epoch 93/5000\n",
      "1597/1597 [==============================] - 0s 283us/sample - loss: 0.1149 - R2: 0.7261 - val_loss: 0.0700 - val_R2: 0.8670\n",
      "Epoch 94/5000\n",
      "1597/1597 [==============================] - 0s 280us/sample - loss: 0.1194 - R2: 0.6786 - val_loss: 0.0747 - val_R2: 0.8774\n",
      "Epoch 95/5000\n",
      "1597/1597 [==============================] - 0s 280us/sample - loss: 0.1161 - R2: 0.7674 - val_loss: 0.0707 - val_R2: 0.8335\n",
      "Epoch 96/5000\n",
      "1597/1597 [==============================] - 0s 296us/sample - loss: 0.1164 - R2: 0.7323 - val_loss: 0.0687 - val_R2: 0.7943\n",
      "Epoch 97/5000\n",
      "1597/1597 [==============================] - 0s 300us/sample - loss: 0.1150 - R2: 0.6924 - val_loss: 0.0739 - val_R2: 0.8636\n",
      "Epoch 98/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.1144 - R2: 0.7321 - val_loss: 0.0799 - val_R2: 0.8344\n",
      "Epoch 99/5000\n",
      "1597/1597 [==============================] - 0s 279us/sample - loss: 0.1137 - R2: 0.6951 - val_loss: 0.0710 - val_R2: 0.8740\n",
      "Epoch 100/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.1128 - R2: 0.7383 - val_loss: 0.0707 - val_R2: 0.7809\n",
      "Epoch 101/5000\n",
      "1597/1597 [==============================] - 0s 278us/sample - loss: 0.1151 - R2: 0.7112 - val_loss: 0.0663 - val_R2: 0.8299\n",
      "Epoch 102/5000\n",
      "1597/1597 [==============================] - 0s 277us/sample - loss: 0.1147 - R2: 0.7007 - val_loss: 0.0793 - val_R2: 0.8913\n",
      "Epoch 103/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.1141 - R2: 0.7064 - val_loss: 0.0737 - val_R2: 0.8558\n",
      "Epoch 104/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.1135 - R2: 0.7454 - val_loss: 0.0663 - val_R2: 0.8487\n",
      "Epoch 105/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.1127 - R2: 0.7566 - val_loss: 0.0696 - val_R2: 0.8728\n",
      "Epoch 106/5000\n",
      "1597/1597 [==============================] - 0s 297us/sample - loss: 0.1126 - R2: 0.7354 - val_loss: 0.0685 - val_R2: 0.8330\n",
      "Epoch 107/5000\n",
      "1597/1597 [==============================] - 0s 278us/sample - loss: 0.1132 - R2: 0.7218 - val_loss: 0.0705 - val_R2: 0.7802\n",
      "Epoch 108/5000\n",
      "1597/1597 [==============================] - 0s 272us/sample - loss: 0.1099 - R2: 0.7110 - val_loss: 0.0655 - val_R2: 0.8846\n",
      "Epoch 109/5000\n",
      "1597/1597 [==============================] - 0s 280us/sample - loss: 0.1080 - R2: 0.7773 - val_loss: 0.0613 - val_R2: 0.8431\n",
      "Epoch 110/5000\n",
      "1597/1597 [==============================] - 0s 274us/sample - loss: 0.1080 - R2: 0.7588 - val_loss: 0.0636 - val_R2: 0.8276\n",
      "Epoch 111/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.1074 - R2: 0.7085 - val_loss: 0.0733 - val_R2: 0.8560\n",
      "Epoch 112/5000\n",
      "1597/1597 [==============================] - 0s 277us/sample - loss: 0.1104 - R2: 0.7176 - val_loss: 0.0695 - val_R2: 0.8819\n",
      "Epoch 113/5000\n",
      "1597/1597 [==============================] - 0s 283us/sample - loss: 0.1124 - R2: 0.6678 - val_loss: 0.0705 - val_R2: 0.8284\n",
      "Epoch 114/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.1098 - R2: 0.7452 - val_loss: 0.0645 - val_R2: 0.8921\n",
      "Epoch 115/5000\n",
      "1597/1597 [==============================] - 0s 283us/sample - loss: 0.1079 - R2: 0.7671 - val_loss: 0.0610 - val_R2: 0.8168\n",
      "Epoch 116/5000\n",
      "1597/1597 [==============================] - 0s 270us/sample - loss: 0.1056 - R2: 0.7432 - val_loss: 0.0725 - val_R2: 0.8920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/5000\n",
      "1597/1597 [==============================] - 0s 280us/sample - loss: 0.1067 - R2: 0.7667 - val_loss: 0.0634 - val_R2: 0.8893\n",
      "Epoch 118/5000\n",
      "1597/1597 [==============================] - 0s 273us/sample - loss: 0.1051 - R2: 0.7702 - val_loss: 0.0647 - val_R2: 0.8746\n",
      "Epoch 119/5000\n",
      "1597/1597 [==============================] - 0s 282us/sample - loss: 0.1094 - R2: 0.7751 - val_loss: 0.0687 - val_R2: 0.8563\n",
      "Epoch 120/5000\n",
      "1597/1597 [==============================] - 0s 277us/sample - loss: 0.1063 - R2: 0.7610 - val_loss: 0.0626 - val_R2: 0.8643\n",
      "Epoch 121/5000\n",
      "1597/1597 [==============================] - 0s 278us/sample - loss: 0.1091 - R2: 0.7349 - val_loss: 0.0611 - val_R2: 0.8500\n",
      "Epoch 122/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.1083 - R2: 0.7169 - val_loss: 0.0613 - val_R2: 0.8087\n",
      "Epoch 123/5000\n",
      "1597/1597 [==============================] - 0s 297us/sample - loss: 0.1102 - R2: 0.7610 - val_loss: 0.0616 - val_R2: 0.8442\n",
      "Epoch 124/5000\n",
      "1597/1597 [==============================] - 0s 297us/sample - loss: 0.1023 - R2: 0.7109 - val_loss: 0.0672 - val_R2: 0.8901\n",
      "Epoch 125/5000\n",
      "1597/1597 [==============================] - 0s 282us/sample - loss: 0.1033 - R2: 0.7678 - val_loss: 0.0740 - val_R2: 0.8839\n",
      "Epoch 126/5000\n",
      "1597/1597 [==============================] - 0s 300us/sample - loss: 0.1035 - R2: 0.7622 - val_loss: 0.0602 - val_R2: 0.8677\n",
      "Epoch 127/5000\n",
      "1597/1597 [==============================] - 0s 275us/sample - loss: 0.0994 - R2: 0.7862 - val_loss: 0.0707 - val_R2: 0.8758\n",
      "Epoch 128/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.1056 - R2: 0.7538 - val_loss: 0.0708 - val_R2: 0.8878\n",
      "Epoch 129/5000\n",
      "1597/1597 [==============================] - 0s 278us/sample - loss: 0.1023 - R2: 0.7582 - val_loss: 0.0669 - val_R2: 0.8660\n",
      "Epoch 130/5000\n",
      "1597/1597 [==============================] - 0s 280us/sample - loss: 0.1057 - R2: 0.7553 - val_loss: 0.0583 - val_R2: 0.8742\n",
      "Epoch 131/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.1009 - R2: 0.7993 - val_loss: 0.0599 - val_R2: 0.8103\n",
      "Epoch 132/5000\n",
      "1597/1597 [==============================] - 0s 296us/sample - loss: 0.1089 - R2: 0.7479 - val_loss: 0.0680 - val_R2: 0.8834\n",
      "Epoch 133/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.1023 - R2: 0.7667 - val_loss: 0.0544 - val_R2: 0.8703\n",
      "Epoch 134/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.1053 - R2: 0.7351 - val_loss: 0.0555 - val_R2: 0.8635\n",
      "Epoch 135/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.1029 - R2: 0.7720 - val_loss: 0.0579 - val_R2: 0.8656\n",
      "Epoch 136/5000\n",
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.1034 - R2: 0.7545 - val_loss: 0.0613 - val_R2: 0.8344\n",
      "Epoch 137/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.1091 - R2: 0.6946 - val_loss: 0.0653 - val_R2: 0.8789\n",
      "Epoch 138/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.1026 - R2: 0.7501 - val_loss: 0.0538 - val_R2: 0.8933\n",
      "Epoch 139/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0984 - R2: 0.7392 - val_loss: 0.0720 - val_R2: 0.8602\n",
      "Epoch 140/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.1038 - R2: 0.7629 - val_loss: 0.0545 - val_R2: 0.8816\n",
      "Epoch 141/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.1022 - R2: 0.7177 - val_loss: 0.0683 - val_R2: 0.8823\n",
      "Epoch 142/5000\n",
      "1597/1597 [==============================] - 0s 283us/sample - loss: 0.1053 - R2: 0.7705 - val_loss: 0.0600 - val_R2: 0.8392\n",
      "Epoch 143/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.1085 - R2: 0.7569 - val_loss: 0.0547 - val_R2: 0.8453\n",
      "Epoch 144/5000\n",
      "1597/1597 [==============================] - 0s 295us/sample - loss: 0.1015 - R2: 0.7584 - val_loss: 0.0539 - val_R2: 0.8792\n",
      "Epoch 145/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.1011 - R2: 0.7817 - val_loss: 0.0570 - val_R2: 0.9001\n",
      "Epoch 146/5000\n",
      "1597/1597 [==============================] - 0s 284us/sample - loss: 0.1002 - R2: 0.7353 - val_loss: 0.0521 - val_R2: 0.8610\n",
      "Epoch 147/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.1004 - R2: 0.7898 - val_loss: 0.0633 - val_R2: 0.8685\n",
      "Epoch 148/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.1015 - R2: 0.7610 - val_loss: 0.0625 - val_R2: 0.8792\n",
      "Epoch 149/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.1009 - R2: 0.7722 - val_loss: 0.0550 - val_R2: 0.8729\n",
      "Epoch 150/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.1006 - R2: 0.7600 - val_loss: 0.0502 - val_R2: 0.8586\n",
      "Epoch 151/5000\n",
      "1597/1597 [==============================] - 0s 273us/sample - loss: 0.1026 - R2: 0.7653 - val_loss: 0.0557 - val_R2: 0.8707\n",
      "Epoch 152/5000\n",
      "1597/1597 [==============================] - 0s 273us/sample - loss: 0.1020 - R2: 0.7509 - val_loss: 0.0586 - val_R2: 0.8794\n",
      "Epoch 153/5000\n",
      "1597/1597 [==============================] - 0s 277us/sample - loss: 0.1001 - R2: 0.7567 - val_loss: 0.0531 - val_R2: 0.8674\n",
      "Epoch 154/5000\n",
      "1597/1597 [==============================] - 0s 276us/sample - loss: 0.1045 - R2: 0.7344 - val_loss: 0.0678 - val_R2: 0.7503\n",
      "Epoch 155/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.1059 - R2: 0.7383 - val_loss: 0.0508 - val_R2: 0.8779\n",
      "Epoch 156/5000\n",
      "1597/1597 [==============================] - 0s 296us/sample - loss: 0.1043 - R2: 0.7418 - val_loss: 0.0627 - val_R2: 0.8764\n",
      "Epoch 157/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.1048 - R2: 0.7404 - val_loss: 0.0588 - val_R2: 0.8733\n",
      "Epoch 158/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.1012 - R2: 0.7374 - val_loss: 0.0604 - val_R2: 0.8874\n",
      "Epoch 159/5000\n",
      "1597/1597 [==============================] - 0s 279us/sample - loss: 0.0992 - R2: 0.7743 - val_loss: 0.0519 - val_R2: 0.8704\n",
      "Epoch 160/5000\n",
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.1000 - R2: 0.7487 - val_loss: 0.0489 - val_R2: 0.8921\n",
      "Epoch 161/5000\n",
      "1597/1597 [==============================] - 0s 271us/sample - loss: 0.1014 - R2: 0.7385 - val_loss: 0.0577 - val_R2: 0.8937\n",
      "Epoch 162/5000\n",
      "1597/1597 [==============================] - 0s 277us/sample - loss: 0.0993 - R2: 0.7628 - val_loss: 0.0487 - val_R2: 0.8611\n",
      "Epoch 163/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0976 - R2: 0.7289 - val_loss: 0.0471 - val_R2: 0.8792\n",
      "Epoch 164/5000\n",
      "1597/1597 [==============================] - 0s 277us/sample - loss: 0.0969 - R2: 0.7736 - val_loss: 0.0503 - val_R2: 0.8531\n",
      "Epoch 165/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.0954 - R2: 0.7366 - val_loss: 0.0650 - val_R2: 0.8556\n",
      "Epoch 166/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.1025 - R2: 0.7610 - val_loss: 0.0578 - val_R2: 0.8631\n",
      "Epoch 167/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.0991 - R2: 0.7840 - val_loss: 0.0507 - val_R2: 0.8984\n",
      "Epoch 168/5000\n",
      "1597/1597 [==============================] - 0s 282us/sample - loss: 0.0955 - R2: 0.7889 - val_loss: 0.0606 - val_R2: 0.8776\n",
      "Epoch 169/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.1039 - R2: 0.7724 - val_loss: 0.0520 - val_R2: 0.8653\n",
      "Epoch 170/5000\n",
      "1597/1597 [==============================] - 0s 267us/sample - loss: 0.0964 - R2: 0.7546 - val_loss: 0.0496 - val_R2: 0.8913\n",
      "Epoch 171/5000\n",
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.1037 - R2: 0.7297 - val_loss: 0.0533 - val_R2: 0.9029\n",
      "Epoch 172/5000\n",
      "1597/1597 [==============================] - 1s 325us/sample - loss: 0.0969 - R2: 0.7429 - val_loss: 0.0477 - val_R2: 0.8834\n",
      "Epoch 173/5000\n",
      "1597/1597 [==============================] - 0s 311us/sample - loss: 0.0960 - R2: 0.7662 - val_loss: 0.0476 - val_R2: 0.9082\n",
      "Epoch 174/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.0971 - R2: 0.7563 - val_loss: 0.0484 - val_R2: 0.9003\n",
      "Epoch 175/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.0951 - R2: 0.7588 - val_loss: 0.0487 - val_R2: 0.8594\n",
      "Epoch 176/5000\n",
      "1597/1597 [==============================] - 0s 302us/sample - loss: 0.1005 - R2: 0.7399 - val_loss: 0.0548 - val_R2: 0.8056\n",
      "Epoch 177/5000\n",
      "1597/1597 [==============================] - 0s 299us/sample - loss: 0.0996 - R2: 0.7704 - val_loss: 0.0551 - val_R2: 0.8288\n",
      "Epoch 178/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.0963 - R2: 0.7659 - val_loss: 0.0461 - val_R2: 0.8970\n",
      "Epoch 179/5000\n",
      "1597/1597 [==============================] - 0s 281us/sample - loss: 0.0929 - R2: 0.7770 - val_loss: 0.0466 - val_R2: 0.8576\n",
      "Epoch 180/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.0979 - R2: 0.7464 - val_loss: 0.0591 - val_R2: 0.7920\n",
      "Epoch 181/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.0963 - R2: 0.7680 - val_loss: 0.0519 - val_R2: 0.9046\n",
      "Epoch 182/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.0984 - R2: 0.7697 - val_loss: 0.0477 - val_R2: 0.8550\n",
      "Epoch 183/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.0956 - R2: 0.7560 - val_loss: 0.0543 - val_R2: 0.8721\n",
      "Epoch 184/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.0941 - R2: 0.7213 - val_loss: 0.0487 - val_R2: 0.9048\n",
      "Epoch 185/5000\n",
      "1597/1597 [==============================] - 0s 284us/sample - loss: 0.0983 - R2: 0.7650 - val_loss: 0.0453 - val_R2: 0.8939\n",
      "Epoch 186/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.0959 - R2: 0.7451 - val_loss: 0.0522 - val_R2: 0.8759\n",
      "Epoch 187/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.0954 - R2: 0.7445 - val_loss: 0.0462 - val_R2: 0.8893\n",
      "Epoch 188/5000\n",
      "1597/1597 [==============================] - 0s 297us/sample - loss: 0.0980 - R2: 0.7287 - val_loss: 0.0590 - val_R2: 0.8745\n",
      "Epoch 189/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.0908 - R2: 0.8262 - val_loss: 0.0627 - val_R2: 0.7983\n",
      "Epoch 190/5000\n",
      "1597/1597 [==============================] - 0s 292us/sample - loss: 0.1016 - R2: 0.7476 - val_loss: 0.0541 - val_R2: 0.8751\n",
      "Epoch 191/5000\n",
      "1597/1597 [==============================] - 0s 278us/sample - loss: 0.0968 - R2: 0.7415 - val_loss: 0.0530 - val_R2: 0.8766\n",
      "Epoch 192/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.1030 - R2: 0.7452 - val_loss: 0.0488 - val_R2: 0.8677\n",
      "Epoch 193/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0938 - R2: 0.7567 - val_loss: 0.0646 - val_R2: 0.8700\n",
      "Epoch 194/5000\n",
      "1597/1597 [==============================] - 0s 275us/sample - loss: 0.1004 - R2: 0.7510 - val_loss: 0.0538 - val_R2: 0.8294\n",
      "Epoch 195/5000\n",
      "1597/1597 [==============================] - 0s 272us/sample - loss: 0.0926 - R2: 0.7580 - val_loss: 0.0641 - val_R2: 0.8745\n",
      "Epoch 196/5000\n",
      "1597/1597 [==============================] - 0s 271us/sample - loss: 0.1005 - R2: 0.7573 - val_loss: 0.0485 - val_R2: 0.8671\n",
      "Epoch 197/5000\n",
      "1597/1597 [==============================] - 0s 275us/sample - loss: 0.0921 - R2: 0.7960 - val_loss: 0.0443 - val_R2: 0.8970\n",
      "Epoch 198/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.0933 - R2: 0.7714 - val_loss: 0.0547 - val_R2: 0.8663\n",
      "Epoch 199/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.0945 - R2: 0.7668 - val_loss: 0.0506 - val_R2: 0.8810\n",
      "Epoch 200/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.0957 - R2: 0.7778 - val_loss: 0.0467 - val_R2: 0.8617\n",
      "Epoch 201/5000\n",
      "1597/1597 [==============================] - 0s 295us/sample - loss: 0.0967 - R2: 0.7734 - val_loss: 0.0530 - val_R2: 0.8863\n",
      "Epoch 202/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.0978 - R2: 0.7411 - val_loss: 0.0475 - val_R2: 0.8947\n",
      "Epoch 203/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.0917 - R2: 0.7928 - val_loss: 0.0412 - val_R2: 0.8917\n",
      "Epoch 204/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.0956 - R2: 0.7639 - val_loss: 0.0564 - val_R2: 0.8953\n",
      "Epoch 205/5000\n",
      "1597/1597 [==============================] - 0s 283us/sample - loss: 0.0946 - R2: 0.7947 - val_loss: 0.0473 - val_R2: 0.8873\n",
      "Epoch 206/5000\n",
      "1597/1597 [==============================] - 0s 279us/sample - loss: 0.0971 - R2: 0.7456 - val_loss: 0.0466 - val_R2: 0.8451\n",
      "Epoch 207/5000\n",
      "1597/1597 [==============================] - 0s 267us/sample - loss: 0.0937 - R2: 0.7850 - val_loss: 0.0531 - val_R2: 0.8162\n",
      "Epoch 208/5000\n",
      "1597/1597 [==============================] - 0s 278us/sample - loss: 0.0990 - R2: 0.7159 - val_loss: 0.0600 - val_R2: 0.8851\n",
      "Epoch 209/5000\n",
      "1597/1597 [==============================] - 0s 295us/sample - loss: 0.0944 - R2: 0.7645 - val_loss: 0.0473 - val_R2: 0.8851\n",
      "Epoch 210/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.0985 - R2: 0.7649 - val_loss: 0.0416 - val_R2: 0.8892\n",
      "Epoch 211/5000\n",
      "1597/1597 [==============================] - 0s 281us/sample - loss: 0.0937 - R2: 0.7582 - val_loss: 0.0470 - val_R2: 0.8949\n",
      "Epoch 212/5000\n",
      "1597/1597 [==============================] - 0s 272us/sample - loss: 0.0925 - R2: 0.7842 - val_loss: 0.0526 - val_R2: 0.8372\n",
      "Epoch 213/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.1012 - R2: 0.7335 - val_loss: 0.0443 - val_R2: 0.8983\n",
      "Epoch 214/5000\n",
      "1597/1597 [==============================] - 0s 266us/sample - loss: 0.0920 - R2: 0.8021 - val_loss: 0.0485 - val_R2: 0.8780\n",
      "Epoch 215/5000\n",
      "1597/1597 [==============================] - 0s 284us/sample - loss: 0.0916 - R2: 0.7567 - val_loss: 0.0424 - val_R2: 0.9092\n",
      "Epoch 216/5000\n",
      "1597/1597 [==============================] - 0s 284us/sample - loss: 0.0933 - R2: 0.7775 - val_loss: 0.0522 - val_R2: 0.8550\n",
      "Epoch 217/5000\n",
      "1597/1597 [==============================] - 0s 278us/sample - loss: 0.0959 - R2: 0.7780 - val_loss: 0.0449 - val_R2: 0.8944\n",
      "Epoch 218/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0936 - R2: 0.7972 - val_loss: 0.0436 - val_R2: 0.8957\n",
      "Epoch 219/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.0920 - R2: 0.7871 - val_loss: 0.0465 - val_R2: 0.8958\n",
      "Epoch 220/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0909 - R2: 0.7774 - val_loss: 0.0501 - val_R2: 0.8699\n",
      "Epoch 221/5000\n",
      "1597/1597 [==============================] - 0s 268us/sample - loss: 0.0974 - R2: 0.7051 - val_loss: 0.0652 - val_R2: 0.8171\n",
      "Epoch 222/5000\n",
      "1597/1597 [==============================] - 0s 269us/sample - loss: 0.0914 - R2: 0.8210 - val_loss: 0.0494 - val_R2: 0.9019\n",
      "Epoch 223/5000\n",
      "1597/1597 [==============================] - 0s 273us/sample - loss: 0.0919 - R2: 0.7581 - val_loss: 0.0412 - val_R2: 0.8820\n",
      "Epoch 224/5000\n",
      "1597/1597 [==============================] - 0s 271us/sample - loss: 0.0905 - R2: 0.7736 - val_loss: 0.0468 - val_R2: 0.8925\n",
      "Epoch 225/5000\n",
      "1597/1597 [==============================] - 0s 258us/sample - loss: 0.0884 - R2: 0.7786 - val_loss: 0.0491 - val_R2: 0.8256\n",
      "Epoch 226/5000\n",
      "1597/1597 [==============================] - 0s 284us/sample - loss: 0.0871 - R2: 0.7808 - val_loss: 0.0441 - val_R2: 0.9061\n",
      "Epoch 227/5000\n",
      "1597/1597 [==============================] - 0s 300us/sample - loss: 0.0916 - R2: 0.7888 - val_loss: 0.0477 - val_R2: 0.8688\n",
      "Epoch 228/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.0905 - R2: 0.7710 - val_loss: 0.0414 - val_R2: 0.8836\n",
      "Epoch 229/5000\n",
      "1597/1597 [==============================] - 0s 281us/sample - loss: 0.0916 - R2: 0.7733 - val_loss: 0.0415 - val_R2: 0.8785\n",
      "Epoch 230/5000\n",
      "1597/1597 [==============================] - 0s 282us/sample - loss: 0.0883 - R2: 0.7827 - val_loss: 0.0419 - val_R2: 0.8664\n",
      "Epoch 231/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0932 - R2: 0.7472 - val_loss: 0.0408 - val_R2: 0.9003\n",
      "Epoch 232/5000\n",
      "1597/1597 [==============================] - 0s 299us/sample - loss: 0.0926 - R2: 0.7839 - val_loss: 0.0561 - val_R2: 0.8827\n",
      "Epoch 233/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.0956 - R2: 0.7867 - val_loss: 0.0468 - val_R2: 0.8764\n",
      "Epoch 234/5000\n",
      "1597/1597 [==============================] - 0s 282us/sample - loss: 0.0939 - R2: 0.7835 - val_loss: 0.0426 - val_R2: 0.9006\n",
      "Epoch 235/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.0903 - R2: 0.7976 - val_loss: 0.0418 - val_R2: 0.8928\n",
      "Epoch 236/5000\n",
      "1597/1597 [==============================] - 0s 299us/sample - loss: 0.0911 - R2: 0.7535 - val_loss: 0.0408 - val_R2: 0.8953\n",
      "Epoch 237/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.0923 - R2: 0.7870 - val_loss: 0.0418 - val_R2: 0.8823\n",
      "Epoch 238/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.0879 - R2: 0.8146 - val_loss: 0.0384 - val_R2: 0.8855\n",
      "Epoch 239/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.0894 - R2: 0.7822 - val_loss: 0.0461 - val_R2: 0.9070\n",
      "Epoch 240/5000\n",
      "1597/1597 [==============================] - 0s 292us/sample - loss: 0.0862 - R2: 0.8176 - val_loss: 0.0421 - val_R2: 0.8651\n",
      "Epoch 241/5000\n",
      "1597/1597 [==============================] - 0s 284us/sample - loss: 0.0896 - R2: 0.7705 - val_loss: 0.0405 - val_R2: 0.9003\n",
      "Epoch 242/5000\n",
      "1597/1597 [==============================] - 0s 280us/sample - loss: 0.0914 - R2: 0.7495 - val_loss: 0.0475 - val_R2: 0.9067\n",
      "Epoch 243/5000\n",
      "1597/1597 [==============================] - 0s 281us/sample - loss: 0.0877 - R2: 0.7663 - val_loss: 0.0462 - val_R2: 0.8827\n",
      "Epoch 244/5000\n",
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.0943 - R2: 0.7688 - val_loss: 0.0438 - val_R2: 0.9159\n",
      "Epoch 245/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0896 - R2: 0.7892 - val_loss: 0.0384 - val_R2: 0.9136\n",
      "Epoch 246/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.0851 - R2: 0.8297 - val_loss: 0.0397 - val_R2: 0.9003\n",
      "Epoch 247/5000\n",
      "1597/1597 [==============================] - 0s 292us/sample - loss: 0.0924 - R2: 0.8195 - val_loss: 0.0413 - val_R2: 0.9021\n",
      "Epoch 248/5000\n",
      "1597/1597 [==============================] - 0s 312us/sample - loss: 0.0878 - R2: 0.7641 - val_loss: 0.0443 - val_R2: 0.9105\n",
      "Epoch 249/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.0886 - R2: 0.7712 - val_loss: 0.0403 - val_R2: 0.9079\n",
      "Epoch 250/5000\n",
      "1597/1597 [==============================] - 0s 281us/sample - loss: 0.0909 - R2: 0.7620 - val_loss: 0.0424 - val_R2: 0.8912\n",
      "Epoch 251/5000\n",
      "1597/1597 [==============================] - 0s 299us/sample - loss: 0.0871 - R2: 0.7986 - val_loss: 0.0427 - val_R2: 0.8917\n",
      "Epoch 252/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.0920 - R2: 0.7266 - val_loss: 0.0452 - val_R2: 0.8964\n",
      "Epoch 253/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.0893 - R2: 0.7678 - val_loss: 0.0423 - val_R2: 0.8617\n",
      "Epoch 254/5000\n",
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.0868 - R2: 0.7868 - val_loss: 0.0370 - val_R2: 0.9028\n",
      "Epoch 255/5000\n",
      "1597/1597 [==============================] - 0s 273us/sample - loss: 0.0881 - R2: 0.7752 - val_loss: 0.0393 - val_R2: 0.8908\n",
      "Epoch 256/5000\n",
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.0887 - R2: 0.7826 - val_loss: 0.0421 - val_R2: 0.9174\n",
      "Epoch 257/5000\n",
      "1597/1597 [==============================] - 0s 299us/sample - loss: 0.0892 - R2: 0.7876 - val_loss: 0.0361 - val_R2: 0.9159\n",
      "Epoch 258/5000\n",
      "1597/1597 [==============================] - 0s 300us/sample - loss: 0.0850 - R2: 0.7952 - val_loss: 0.0371 - val_R2: 0.9051\n",
      "Epoch 259/5000\n",
      "1597/1597 [==============================] - 0s 283us/sample - loss: 0.0859 - R2: 0.8105 - val_loss: 0.0401 - val_R2: 0.8868\n",
      "Epoch 260/5000\n",
      "1597/1597 [==============================] - 0s 284us/sample - loss: 0.0823 - R2: 0.7761 - val_loss: 0.0452 - val_R2: 0.9254\n",
      "Epoch 261/5000\n",
      "1597/1597 [==============================] - 0s 283us/sample - loss: 0.0844 - R2: 0.7876 - val_loss: 0.0392 - val_R2: 0.9202\n",
      "Epoch 262/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.0895 - R2: 0.7854 - val_loss: 0.0451 - val_R2: 0.8977\n",
      "Epoch 263/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.0828 - R2: 0.7987 - val_loss: 0.0365 - val_R2: 0.8963\n",
      "Epoch 264/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.0863 - R2: 0.7976 - val_loss: 0.0639 - val_R2: 0.7516\n",
      "Epoch 265/5000\n",
      "1597/1597 [==============================] - 0s 304us/sample - loss: 0.0959 - R2: 0.7556 - val_loss: 0.0345 - val_R2: 0.9263\n",
      "Epoch 266/5000\n",
      "1597/1597 [==============================] - 0s 311us/sample - loss: 0.0820 - R2: 0.8132 - val_loss: 0.0397 - val_R2: 0.9151\n",
      "Epoch 267/5000\n",
      "1597/1597 [==============================] - 0s 305us/sample - loss: 0.0833 - R2: 0.8361 - val_loss: 0.0351 - val_R2: 0.9086\n",
      "Epoch 268/5000\n",
      "1597/1597 [==============================] - 0s 309us/sample - loss: 0.0838 - R2: 0.8183 - val_loss: 0.0435 - val_R2: 0.9248\n",
      "Epoch 269/5000\n",
      "1597/1597 [==============================] - 0s 301us/sample - loss: 0.0866 - R2: 0.8285 - val_loss: 0.0357 - val_R2: 0.9037\n",
      "Epoch 270/5000\n",
      "1597/1597 [==============================] - 0s 292us/sample - loss: 0.0844 - R2: 0.7963 - val_loss: 0.0380 - val_R2: 0.8843\n",
      "Epoch 271/5000\n",
      "1597/1597 [==============================] - 0s 296us/sample - loss: 0.0864 - R2: 0.7588 - val_loss: 0.0441 - val_R2: 0.8976\n",
      "Epoch 272/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.0873 - R2: 0.7816 - val_loss: 0.0512 - val_R2: 0.9072\n",
      "Epoch 273/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.0841 - R2: 0.8029 - val_loss: 0.0389 - val_R2: 0.9375\n",
      "Epoch 274/5000\n",
      "1597/1597 [==============================] - 0s 297us/sample - loss: 0.0829 - R2: 0.8042 - val_loss: 0.0344 - val_R2: 0.8933\n",
      "Epoch 275/5000\n",
      "1597/1597 [==============================] - 0s 305us/sample - loss: 0.0811 - R2: 0.8026 - val_loss: 0.0354 - val_R2: 0.9250\n",
      "Epoch 276/5000\n",
      "1597/1597 [==============================] - 0s 292us/sample - loss: 0.0835 - R2: 0.7904 - val_loss: 0.0433 - val_R2: 0.8948\n",
      "Epoch 277/5000\n",
      "1597/1597 [==============================] - 0s 281us/sample - loss: 0.0851 - R2: 0.7911 - val_loss: 0.0428 - val_R2: 0.9430\n",
      "Epoch 278/5000\n",
      "1597/1597 [==============================] - 0s 292us/sample - loss: 0.0830 - R2: 0.8207 - val_loss: 0.0680 - val_R2: 0.7394\n",
      "Epoch 279/5000\n",
      "1597/1597 [==============================] - 0s 302us/sample - loss: 0.0899 - R2: 0.7824 - val_loss: 0.0377 - val_R2: 0.9040\n",
      "Epoch 280/5000\n",
      "1597/1597 [==============================] - 0s 296us/sample - loss: 0.0820 - R2: 0.8156 - val_loss: 0.0336 - val_R2: 0.9163\n",
      "Epoch 281/5000\n",
      "1597/1597 [==============================] - 0s 297us/sample - loss: 0.0775 - R2: 0.8327 - val_loss: 0.0400 - val_R2: 0.8778\n",
      "Epoch 282/5000\n",
      "1597/1597 [==============================] - 0s 283us/sample - loss: 0.0806 - R2: 0.8146 - val_loss: 0.0420 - val_R2: 0.9274\n",
      "Epoch 283/5000\n",
      "1597/1597 [==============================] - 0s 281us/sample - loss: 0.0836 - R2: 0.8219 - val_loss: 0.0332 - val_R2: 0.9359\n",
      "Epoch 284/5000\n",
      "1597/1597 [==============================] - 0s 268us/sample - loss: 0.0798 - R2: 0.8312 - val_loss: 0.0524 - val_R2: 0.8903\n",
      "Epoch 285/5000\n",
      "1597/1597 [==============================] - 0s 272us/sample - loss: 0.0819 - R2: 0.7962 - val_loss: 0.0394 - val_R2: 0.9304\n",
      "Epoch 286/5000\n",
      "1597/1597 [==============================] - 0s 270us/sample - loss: 0.0799 - R2: 0.7869 - val_loss: 0.0463 - val_R2: 0.9073\n",
      "Epoch 287/5000\n",
      "1597/1597 [==============================] - 0s 308us/sample - loss: 0.0862 - R2: 0.7793 - val_loss: 0.0377 - val_R2: 0.9198\n",
      "Epoch 288/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.0805 - R2: 0.8082 - val_loss: 0.0451 - val_R2: 0.9183\n",
      "Epoch 289/5000\n",
      "1597/1597 [==============================] - 0s 277us/sample - loss: 0.0811 - R2: 0.8301 - val_loss: 0.0346 - val_R2: 0.9263\n",
      "Epoch 290/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0826 - R2: 0.8039 - val_loss: 0.0340 - val_R2: 0.9330\n",
      "Epoch 291/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 0s 305us/sample - loss: 0.0803 - R2: 0.8085 - val_loss: 0.0374 - val_R2: 0.9093\n",
      "Epoch 292/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.0839 - R2: 0.7948 - val_loss: 0.0396 - val_R2: 0.8891\n",
      "Epoch 293/5000\n",
      "1597/1597 [==============================] - 0s 299us/sample - loss: 0.0783 - R2: 0.8461 - val_loss: 0.0322 - val_R2: 0.9230\n",
      "Epoch 294/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.0829 - R2: 0.8347 - val_loss: 0.0404 - val_R2: 0.8784\n",
      "Epoch 295/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.0783 - R2: 0.7942 - val_loss: 0.0447 - val_R2: 0.8691\n",
      "Epoch 296/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.0789 - R2: 0.8374 - val_loss: 0.0354 - val_R2: 0.9099\n",
      "Epoch 297/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0816 - R2: 0.8360 - val_loss: 0.0324 - val_R2: 0.9390\n",
      "Epoch 298/5000\n",
      "1597/1597 [==============================] - 0s 279us/sample - loss: 0.0777 - R2: 0.8168 - val_loss: 0.0412 - val_R2: 0.9268\n",
      "Epoch 299/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.0771 - R2: 0.8593 - val_loss: 0.0459 - val_R2: 0.9230\n",
      "Epoch 300/5000\n",
      "1597/1597 [==============================] - 0s 276us/sample - loss: 0.0795 - R2: 0.8387 - val_loss: 0.0425 - val_R2: 0.9404\n",
      "Epoch 301/5000\n",
      "1597/1597 [==============================] - 0s 280us/sample - loss: 0.0754 - R2: 0.8218 - val_loss: 0.0306 - val_R2: 0.9236\n",
      "Epoch 302/5000\n",
      "1597/1597 [==============================] - 0s 275us/sample - loss: 0.0771 - R2: 0.8524 - val_loss: 0.0444 - val_R2: 0.9220\n",
      "Epoch 303/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.0800 - R2: 0.8414 - val_loss: 0.0313 - val_R2: 0.9156\n",
      "Epoch 304/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.0808 - R2: 0.7985 - val_loss: 0.0334 - val_R2: 0.9426\n",
      "Epoch 305/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.0786 - R2: 0.8328 - val_loss: 0.0343 - val_R2: 0.9201\n",
      "Epoch 306/5000\n",
      "1597/1597 [==============================] - 0s 299us/sample - loss: 0.0778 - R2: 0.8425 - val_loss: 0.0394 - val_R2: 0.9346\n",
      "Epoch 307/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.0785 - R2: 0.8389 - val_loss: 0.0322 - val_R2: 0.9380\n",
      "Epoch 308/5000\n",
      "1597/1597 [==============================] - 0s 277us/sample - loss: 0.0753 - R2: 0.7913 - val_loss: 0.0359 - val_R2: 0.9161\n",
      "Epoch 309/5000\n",
      "1597/1597 [==============================] - 0s 283us/sample - loss: 0.0755 - R2: 0.8260 - val_loss: 0.0314 - val_R2: 0.9019\n",
      "Epoch 310/5000\n",
      "1597/1597 [==============================] - 0s 272us/sample - loss: 0.0807 - R2: 0.8126 - val_loss: 0.0368 - val_R2: 0.9468\n",
      "Epoch 311/5000\n",
      "1597/1597 [==============================] - 0s 280us/sample - loss: 0.0814 - R2: 0.7883 - val_loss: 0.0312 - val_R2: 0.9209\n",
      "Epoch 312/5000\n",
      "1597/1597 [==============================] - 0s 278us/sample - loss: 0.0781 - R2: 0.8276 - val_loss: 0.0342 - val_R2: 0.9445\n",
      "Epoch 313/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.0786 - R2: 0.8448 - val_loss: 0.0343 - val_R2: 0.9161\n",
      "Epoch 314/5000\n",
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.0732 - R2: 0.8232 - val_loss: 0.0406 - val_R2: 0.9286\n",
      "Epoch 315/5000\n",
      "1597/1597 [==============================] - 0s 275us/sample - loss: 0.0738 - R2: 0.8505 - val_loss: 0.0314 - val_R2: 0.9147\n",
      "Epoch 316/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0769 - R2: 0.8547 - val_loss: 0.0305 - val_R2: 0.9444\n",
      "Epoch 317/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.0760 - R2: 0.8069 - val_loss: 0.0367 - val_R2: 0.9390\n",
      "Epoch 318/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.0711 - R2: 0.8309 - val_loss: 0.0355 - val_R2: 0.8892\n",
      "Epoch 319/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.0726 - R2: 0.8078 - val_loss: 0.0352 - val_R2: 0.9304\n",
      "Epoch 320/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.0712 - R2: 0.8422 - val_loss: 0.0317 - val_R2: 0.9369\n",
      "Epoch 321/5000\n",
      "1597/1597 [==============================] - 0s 282us/sample - loss: 0.0714 - R2: 0.8288 - val_loss: 0.0484 - val_R2: 0.9421\n",
      "Epoch 322/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.0770 - R2: 0.8137 - val_loss: 0.0343 - val_R2: 0.9499\n",
      "Epoch 323/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0736 - R2: 0.8401 - val_loss: 0.0288 - val_R2: 0.9341\n",
      "Epoch 324/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.0784 - R2: 0.8521 - val_loss: 0.0348 - val_R2: 0.8898\n",
      "Epoch 325/5000\n",
      "1597/1597 [==============================] - 0s 292us/sample - loss: 0.0832 - R2: 0.7843 - val_loss: 0.0269 - val_R2: 0.9383\n",
      "Epoch 326/5000\n",
      "1597/1597 [==============================] - 0s 269us/sample - loss: 0.0740 - R2: 0.8314 - val_loss: 0.0310 - val_R2: 0.9316\n",
      "Epoch 327/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.0729 - R2: 0.8567 - val_loss: 0.0309 - val_R2: 0.9498\n",
      "Epoch 328/5000\n",
      "1597/1597 [==============================] - 0s 302us/sample - loss: 0.0782 - R2: 0.7962 - val_loss: 0.0312 - val_R2: 0.9223\n",
      "Epoch 329/5000\n",
      "1597/1597 [==============================] - 0s 301us/sample - loss: 0.0756 - R2: 0.8358 - val_loss: 0.0376 - val_R2: 0.9180\n",
      "Epoch 330/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.0751 - R2: 0.8039 - val_loss: 0.0347 - val_R2: 0.9526\n",
      "Epoch 331/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.0727 - R2: 0.8359 - val_loss: 0.0319 - val_R2: 0.9387\n",
      "Epoch 332/5000\n",
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.0745 - R2: 0.8293 - val_loss: 0.0314 - val_R2: 0.9342\n",
      "Epoch 333/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.0735 - R2: 0.8294 - val_loss: 0.0263 - val_R2: 0.9426\n",
      "Epoch 334/5000\n",
      "1597/1597 [==============================] - 0s 272us/sample - loss: 0.0769 - R2: 0.7925 - val_loss: 0.0348 - val_R2: 0.8901\n",
      "Epoch 335/5000\n",
      "1597/1597 [==============================] - 0s 278us/sample - loss: 0.0707 - R2: 0.8235 - val_loss: 0.0289 - val_R2: 0.9475\n",
      "Epoch 336/5000\n",
      "1597/1597 [==============================] - 0s 280us/sample - loss: 0.0789 - R2: 0.8214 - val_loss: 0.0280 - val_R2: 0.9316\n",
      "Epoch 337/5000\n",
      "1597/1597 [==============================] - 0s 278us/sample - loss: 0.0700 - R2: 0.8441 - val_loss: 0.0384 - val_R2: 0.8472\n",
      "Epoch 338/5000\n",
      "1597/1597 [==============================] - 0s 279us/sample - loss: 0.0747 - R2: 0.8242 - val_loss: 0.0295 - val_R2: 0.9221\n",
      "Epoch 339/5000\n",
      "1597/1597 [==============================] - 0s 299us/sample - loss: 0.0728 - R2: 0.8243 - val_loss: 0.0300 - val_R2: 0.9301\n",
      "Epoch 340/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.0693 - R2: 0.8877 - val_loss: 0.0312 - val_R2: 0.9240\n",
      "Epoch 341/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0704 - R2: 0.8252 - val_loss: 0.0313 - val_R2: 0.8956\n",
      "Epoch 342/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.0713 - R2: 0.8557 - val_loss: 0.0273 - val_R2: 0.9275\n",
      "Epoch 343/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.0710 - R2: 0.8175 - val_loss: 0.0348 - val_R2: 0.9332\n",
      "Epoch 344/5000\n",
      "1597/1597 [==============================] - 0s 296us/sample - loss: 0.0706 - R2: 0.8672 - val_loss: 0.0332 - val_R2: 0.9451\n",
      "Epoch 345/5000\n",
      "1597/1597 [==============================] - 0s 281us/sample - loss: 0.0692 - R2: 0.8443 - val_loss: 0.0378 - val_R2: 0.8579\n",
      "Epoch 346/5000\n",
      "1597/1597 [==============================] - 0s 267us/sample - loss: 0.0715 - R2: 0.8292 - val_loss: 0.0289 - val_R2: 0.9235\n",
      "Epoch 347/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.0732 - R2: 0.8071 - val_loss: 0.0373 - val_R2: 0.8970\n",
      "Epoch 348/5000\n",
      "1597/1597 [==============================] - 0s 296us/sample - loss: 0.0656 - R2: 0.8426 - val_loss: 0.0282 - val_R2: 0.9517\n",
      "Epoch 349/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 0s 300us/sample - loss: 0.0675 - R2: 0.8217 - val_loss: 0.0311 - val_R2: 0.9502\n",
      "Epoch 350/5000\n",
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.0654 - R2: 0.8830 - val_loss: 0.0267 - val_R2: 0.9337\n",
      "Epoch 351/5000\n",
      "1597/1597 [==============================] - 0s 281us/sample - loss: 0.0664 - R2: 0.8268 - val_loss: 0.0308 - val_R2: 0.9532\n",
      "Epoch 352/5000\n",
      "1597/1597 [==============================] - 0s 264us/sample - loss: 0.0662 - R2: 0.8774 - val_loss: 0.0313 - val_R2: 0.9546\n",
      "Epoch 353/5000\n",
      "1597/1597 [==============================] - 0s 274us/sample - loss: 0.0759 - R2: 0.8108 - val_loss: 0.0367 - val_R2: 0.9211\n",
      "Epoch 354/5000\n",
      "1597/1597 [==============================] - 0s 302us/sample - loss: 0.0691 - R2: 0.8544 - val_loss: 0.0250 - val_R2: 0.9463\n",
      "Epoch 355/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0725 - R2: 0.8249 - val_loss: 0.0278 - val_R2: 0.9235\n",
      "Epoch 356/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.0714 - R2: 0.8460 - val_loss: 0.0343 - val_R2: 0.9552\n",
      "Epoch 357/5000\n",
      "1597/1597 [==============================] - 0s 297us/sample - loss: 0.0725 - R2: 0.8203 - val_loss: 0.0294 - val_R2: 0.9541\n",
      "Epoch 358/5000\n",
      "1597/1597 [==============================] - 0s 304us/sample - loss: 0.0763 - R2: 0.8489 - val_loss: 0.0320 - val_R2: 0.9475\n",
      "Epoch 359/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.0644 - R2: 0.8793 - val_loss: 0.0269 - val_R2: 0.9304\n",
      "Epoch 360/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.0649 - R2: 0.8565 - val_loss: 0.0262 - val_R2: 0.9203\n",
      "Epoch 361/5000\n",
      "1597/1597 [==============================] - 0s 297us/sample - loss: 0.0712 - R2: 0.8126 - val_loss: 0.0490 - val_R2: 0.9203\n",
      "Epoch 362/5000\n",
      "1597/1597 [==============================] - 0s 296us/sample - loss: 0.0717 - R2: 0.8242 - val_loss: 0.0280 - val_R2: 0.9492\n",
      "Epoch 363/5000\n",
      "1597/1597 [==============================] - 1s 316us/sample - loss: 0.0725 - R2: 0.8390 - val_loss: 0.0288 - val_R2: 0.9499\n",
      "Epoch 364/5000\n",
      "1597/1597 [==============================] - 0s 295us/sample - loss: 0.0619 - R2: 0.8865 - val_loss: 0.0359 - val_R2: 0.9479\n",
      "Epoch 365/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.0653 - R2: 0.8605 - val_loss: 0.0311 - val_R2: 0.8987\n",
      "Epoch 366/5000\n",
      "1597/1597 [==============================] - 0s 296us/sample - loss: 0.0666 - R2: 0.8748 - val_loss: 0.0295 - val_R2: 0.9513\n",
      "Epoch 367/5000\n",
      "1597/1597 [==============================] - 0s 295us/sample - loss: 0.0661 - R2: 0.8708 - val_loss: 0.0334 - val_R2: 0.9056\n",
      "Epoch 368/5000\n",
      "1597/1597 [==============================] - 0s 304us/sample - loss: 0.0690 - R2: 0.8569 - val_loss: 0.0304 - val_R2: 0.9638\n",
      "Epoch 369/5000\n",
      "1597/1597 [==============================] - 0s 280us/sample - loss: 0.0660 - R2: 0.8355 - val_loss: 0.0257 - val_R2: 0.9484\n",
      "Epoch 370/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.0668 - R2: 0.8499 - val_loss: 0.0300 - val_R2: 0.9227\n",
      "Epoch 371/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.0670 - R2: 0.8813 - val_loss: 0.0299 - val_R2: 0.9211\n",
      "Epoch 372/5000\n",
      "1597/1597 [==============================] - 0s 300us/sample - loss: 0.0645 - R2: 0.8243 - val_loss: 0.0312 - val_R2: 0.9239\n",
      "Epoch 373/5000\n",
      "1597/1597 [==============================] - 0s 303us/sample - loss: 0.0647 - R2: 0.8614 - val_loss: 0.0243 - val_R2: 0.9479\n",
      "Epoch 374/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.0652 - R2: 0.8486 - val_loss: 0.0250 - val_R2: 0.9601\n",
      "Epoch 375/5000\n",
      "1597/1597 [==============================] - 0s 301us/sample - loss: 0.0643 - R2: 0.8451 - val_loss: 0.0266 - val_R2: 0.9423\n",
      "Epoch 376/5000\n",
      "1597/1597 [==============================] - 0s 307us/sample - loss: 0.0654 - R2: 0.8378 - val_loss: 0.0253 - val_R2: 0.9497\n",
      "Epoch 377/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.0642 - R2: 0.8841 - val_loss: 0.0250 - val_R2: 0.9473\n",
      "Epoch 378/5000\n",
      "1597/1597 [==============================] - 0s 306us/sample - loss: 0.0642 - R2: 0.8368 - val_loss: 0.0244 - val_R2: 0.9499\n",
      "Epoch 379/5000\n",
      "1597/1597 [==============================] - 0s 300us/sample - loss: 0.0634 - R2: 0.8836 - val_loss: 0.0256 - val_R2: 0.9425\n",
      "Epoch 380/5000\n",
      "1597/1597 [==============================] - 0s 299us/sample - loss: 0.0700 - R2: 0.8548 - val_loss: 0.0296 - val_R2: 0.9265\n",
      "Epoch 381/5000\n",
      "1597/1597 [==============================] - 0s 311us/sample - loss: 0.0663 - R2: 0.8186 - val_loss: 0.0310 - val_R2: 0.9183\n",
      "Epoch 382/5000\n",
      "1597/1597 [==============================] - 0s 303us/sample - loss: 0.0648 - R2: 0.8554 - val_loss: 0.0294 - val_R2: 0.9043\n",
      "Epoch 383/5000\n",
      "1597/1597 [==============================] - 0s 304us/sample - loss: 0.0682 - R2: 0.8196 - val_loss: 0.0335 - val_R2: 0.9448\n",
      "Epoch 384/5000\n",
      "1597/1597 [==============================] - 0s 307us/sample - loss: 0.0629 - R2: 0.8399 - val_loss: 0.0326 - val_R2: 0.9542\n",
      "Epoch 385/5000\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.0637 - R2: 0.90 - 0s 290us/sample - loss: 0.0608 - R2: 0.9046 - val_loss: 0.0270 - val_R2: 0.9472\n",
      "Epoch 386/5000\n",
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.0655 - R2: 0.8608 - val_loss: 0.0272 - val_R2: 0.9596\n",
      "Epoch 387/5000\n",
      "1597/1597 [==============================] - 1s 322us/sample - loss: 0.0618 - R2: 0.8460 - val_loss: 0.0321 - val_R2: 0.8903\n",
      "Epoch 388/5000\n",
      "1597/1597 [==============================] - 1s 326us/sample - loss: 0.0629 - R2: 0.8698 - val_loss: 0.0283 - val_R2: 0.9485\n",
      "Epoch 389/5000\n",
      "1597/1597 [==============================] - 0s 310us/sample - loss: 0.0626 - R2: 0.8519 - val_loss: 0.0246 - val_R2: 0.9450\n",
      "Epoch 390/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.0645 - R2: 0.8765 - val_loss: 0.0296 - val_R2: 0.9451\n",
      "Epoch 391/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.0600 - R2: 0.8529 - val_loss: 0.0282 - val_R2: 0.9605\n",
      "Epoch 392/5000\n",
      "1597/1597 [==============================] - 0s 306us/sample - loss: 0.0656 - R2: 0.9022 - val_loss: 0.0317 - val_R2: 0.9577\n",
      "Epoch 393/5000\n",
      "1597/1597 [==============================] - 0s 297us/sample - loss: 0.0603 - R2: 0.8559 - val_loss: 0.0253 - val_R2: 0.9437\n",
      "Epoch 394/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.0616 - R2: 0.8765 - val_loss: 0.0252 - val_R2: 0.9644\n",
      "Epoch 395/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.0602 - R2: 0.8554 - val_loss: 0.0240 - val_R2: 0.9474\n",
      "Epoch 396/5000\n",
      "1597/1597 [==============================] - 0s 269us/sample - loss: 0.0635 - R2: 0.8497 - val_loss: 0.0236 - val_R2: 0.9519\n",
      "Epoch 397/5000\n",
      "1597/1597 [==============================] - 0s 266us/sample - loss: 0.0586 - R2: 0.8864 - val_loss: 0.0234 - val_R2: 0.9632\n",
      "Epoch 398/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.0648 - R2: 0.8283 - val_loss: 0.0240 - val_R2: 0.9493\n",
      "Epoch 399/5000\n",
      "1597/1597 [==============================] - 0s 299us/sample - loss: 0.0611 - R2: 0.8622 - val_loss: 0.0249 - val_R2: 0.9369\n",
      "Epoch 400/5000\n",
      "1597/1597 [==============================] - 0s 284us/sample - loss: 0.0620 - R2: 0.8601 - val_loss: 0.0225 - val_R2: 0.9558\n",
      "Epoch 401/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.0596 - R2: 0.8542 - val_loss: 0.0257 - val_R2: 0.9639\n",
      "Epoch 402/5000\n",
      "1597/1597 [==============================] - 1s 319us/sample - loss: 0.0589 - R2: 0.8975 - val_loss: 0.0223 - val_R2: 0.9536\n",
      "Epoch 403/5000\n",
      "1597/1597 [==============================] - 1s 327us/sample - loss: 0.0578 - R2: 0.8938 - val_loss: 0.0207 - val_R2: 0.9643\n",
      "Epoch 404/5000\n",
      "1597/1597 [==============================] - 0s 267us/sample - loss: 0.0611 - R2: 0.8943 - val_loss: 0.0310 - val_R2: 0.9358\n",
      "Epoch 405/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.0603 - R2: 0.8708 - val_loss: 0.0271 - val_R2: 0.9573\n",
      "Epoch 406/5000\n",
      "1597/1597 [==============================] - 0s 310us/sample - loss: 0.0610 - R2: 0.8670 - val_loss: 0.0261 - val_R2: 0.9551\n",
      "Epoch 407/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.0599 - R2: 0.9013 - val_loss: 0.0387 - val_R2: 0.9315\n",
      "Epoch 408/5000\n",
      "1597/1597 [==============================] - 0s 275us/sample - loss: 0.0602 - R2: 0.9054 - val_loss: 0.0224 - val_R2: 0.9460\n",
      "Epoch 409/5000\n",
      "1597/1597 [==============================] - 0s 265us/sample - loss: 0.0635 - R2: 0.8954 - val_loss: 0.0214 - val_R2: 0.9615\n",
      "Epoch 410/5000\n",
      "1597/1597 [==============================] - 0s 275us/sample - loss: 0.0571 - R2: 0.8967 - val_loss: 0.0298 - val_R2: 0.9048\n",
      "Epoch 411/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.0594 - R2: 0.8783 - val_loss: 0.0247 - val_R2: 0.9319\n",
      "Epoch 412/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.0566 - R2: 0.8912 - val_loss: 0.0335 - val_R2: 0.9347\n",
      "Epoch 413/5000\n",
      "1597/1597 [==============================] - 0s 304us/sample - loss: 0.0604 - R2: 0.8594 - val_loss: 0.0234 - val_R2: 0.9652\n",
      "Epoch 414/5000\n",
      "1597/1597 [==============================] - 0s 302us/sample - loss: 0.0589 - R2: 0.8789 - val_loss: 0.0235 - val_R2: 0.9336\n",
      "Epoch 415/5000\n",
      "1597/1597 [==============================] - 0s 303us/sample - loss: 0.0591 - R2: 0.8447 - val_loss: 0.0304 - val_R2: 0.9485\n",
      "Epoch 416/5000\n",
      "1597/1597 [==============================] - 0s 303us/sample - loss: 0.0618 - R2: 0.8618 - val_loss: 0.0396 - val_R2: 0.8980\n",
      "Epoch 417/5000\n",
      "1597/1597 [==============================] - 0s 292us/sample - loss: 0.0560 - R2: 0.8769 - val_loss: 0.0203 - val_R2: 0.9571\n",
      "Epoch 418/5000\n",
      "1597/1597 [==============================] - 0s 306us/sample - loss: 0.0578 - R2: 0.9059 - val_loss: 0.0265 - val_R2: 0.9189\n",
      "Epoch 419/5000\n",
      "1597/1597 [==============================] - 1s 320us/sample - loss: 0.0644 - R2: 0.8768 - val_loss: 0.0344 - val_R2: 0.9412\n",
      "Epoch 420/5000\n",
      "1597/1597 [==============================] - 1s 327us/sample - loss: 0.0610 - R2: 0.8545 - val_loss: 0.0280 - val_R2: 0.9448\n",
      "Epoch 421/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.0554 - R2: 0.9088 - val_loss: 0.0209 - val_R2: 0.9481\n",
      "Epoch 422/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.0604 - R2: 0.8534 - val_loss: 0.0337 - val_R2: 0.9228\n",
      "Epoch 423/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.0608 - R2: 0.8590 - val_loss: 0.0306 - val_R2: 0.9622\n",
      "Epoch 424/5000\n",
      "1597/1597 [==============================] - 1s 314us/sample - loss: 0.0580 - R2: 0.8596 - val_loss: 0.0226 - val_R2: 0.9477\n",
      "Epoch 425/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0584 - R2: 0.8504 - val_loss: 0.0198 - val_R2: 0.9610\n",
      "Epoch 426/5000\n",
      "1597/1597 [==============================] - 0s 283us/sample - loss: 0.0547 - R2: 0.9069 - val_loss: 0.0229 - val_R2: 0.9373\n",
      "Epoch 427/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.0564 - R2: 0.8658 - val_loss: 0.0318 - val_R2: 0.9601\n",
      "Epoch 428/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.0595 - R2: 0.8711 - val_loss: 0.0310 - val_R2: 0.9226\n",
      "Epoch 429/5000\n",
      "1597/1597 [==============================] - 0s 283us/sample - loss: 0.0597 - R2: 0.8636 - val_loss: 0.0277 - val_R2: 0.9367\n",
      "Epoch 430/5000\n",
      "1597/1597 [==============================] - 0s 277us/sample - loss: 0.0629 - R2: 0.8379 - val_loss: 0.0231 - val_R2: 0.9380\n",
      "Epoch 431/5000\n",
      "1597/1597 [==============================] - 0s 280us/sample - loss: 0.0607 - R2: 0.8829 - val_loss: 0.0243 - val_R2: 0.9297\n",
      "Epoch 432/5000\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.0631 - R2: 0.8586 - val_loss: 0.0214 - val_R2: 0.9582\n",
      "Epoch 433/5000\n",
      "1597/1597 [==============================] - 0s 297us/sample - loss: 0.0543 - R2: 0.9007 - val_loss: 0.0214 - val_R2: 0.9554\n",
      "Epoch 434/5000\n",
      "1597/1597 [==============================] - 0s 275us/sample - loss: 0.0561 - R2: 0.8644 - val_loss: 0.0227 - val_R2: 0.9713\n",
      "Epoch 435/5000\n",
      "1597/1597 [==============================] - 0s 305us/sample - loss: 0.0643 - R2: 0.8491 - val_loss: 0.0202 - val_R2: 0.9611\n",
      "Epoch 436/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.0547 - R2: 0.8383 - val_loss: 0.0330 - val_R2: 0.9610\n",
      "Epoch 437/5000\n",
      "1597/1597 [==============================] - 0s 281us/sample - loss: 0.0535 - R2: 0.9093 - val_loss: 0.0287 - val_R2: 0.9569\n",
      "Epoch 438/5000\n",
      "1597/1597 [==============================] - 0s 281us/sample - loss: 0.0542 - R2: 0.8686 - val_loss: 0.0251 - val_R2: 0.9624\n",
      "Epoch 439/5000\n",
      "1597/1597 [==============================] - 0s 275us/sample - loss: 0.0549 - R2: 0.9035 - val_loss: 0.0244 - val_R2: 0.9676\n",
      "Epoch 440/5000\n",
      "1597/1597 [==============================] - 0s 282us/sample - loss: 0.0507 - R2: 0.8821 - val_loss: 0.0191 - val_R2: 0.9543\n",
      "Epoch 441/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.0537 - R2: 0.8796 - val_loss: 0.0247 - val_R2: 0.9711\n",
      "Epoch 442/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.0544 - R2: 0.9123 - val_loss: 0.0273 - val_R2: 0.9679\n",
      "Epoch 443/5000\n",
      "1597/1597 [==============================] - 0s 271us/sample - loss: 0.0579 - R2: 0.8953 - val_loss: 0.0194 - val_R2: 0.9663\n",
      "Epoch 444/5000\n",
      "1597/1597 [==============================] - 0s 281us/sample - loss: 0.0521 - R2: 0.9214 - val_loss: 0.0217 - val_R2: 0.9480\n",
      "Epoch 445/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.0515 - R2: 0.9304 - val_loss: 0.0178 - val_R2: 0.9717\n",
      "Epoch 446/5000\n",
      "1597/1597 [==============================] - 0s 279us/sample - loss: 0.0602 - R2: 0.8888 - val_loss: 0.0267 - val_R2: 0.9232\n",
      "Epoch 447/5000\n",
      "1597/1597 [==============================] - 0s 271us/sample - loss: 0.0596 - R2: 0.8710 - val_loss: 0.0275 - val_R2: 0.9430\n",
      "Epoch 448/5000\n",
      "1597/1597 [==============================] - 0s 270us/sample - loss: 0.0561 - R2: 0.8549 - val_loss: 0.0193 - val_R2: 0.9679\n",
      "Epoch 449/5000\n",
      "1597/1597 [==============================] - 0s 279us/sample - loss: 0.0529 - R2: 0.9029 - val_loss: 0.0203 - val_R2: 0.9691\n",
      "Epoch 450/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.0559 - R2: 0.8565 - val_loss: 0.0230 - val_R2: 0.9616\n",
      "Epoch 451/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.0529 - R2: 0.8631 - val_loss: 0.0260 - val_R2: 0.9629\n",
      "Epoch 452/5000\n",
      "1597/1597 [==============================] - 0s 277us/sample - loss: 0.0537 - R2: 0.9132 - val_loss: 0.0218 - val_R2: 0.9373\n",
      "Epoch 453/5000\n",
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.0551 - R2: 0.8999 - val_loss: 0.0219 - val_R2: 0.9664\n",
      "Epoch 454/5000\n",
      "1597/1597 [==============================] - 0s 272us/sample - loss: 0.0512 - R2: 0.9193 - val_loss: 0.0299 - val_R2: 0.8902\n",
      "Epoch 455/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0549 - R2: 0.8636 - val_loss: 0.0206 - val_R2: 0.9504\n",
      "Epoch 456/5000\n",
      "1597/1597 [==============================] - 0s 299us/sample - loss: 0.0524 - R2: 0.9204 - val_loss: 0.0233 - val_R2: 0.9596\n",
      "Epoch 457/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.0530 - R2: 0.8791 - val_loss: 0.0207 - val_R2: 0.9418\n",
      "Epoch 458/5000\n",
      "1597/1597 [==============================] - 0s 284us/sample - loss: 0.0544 - R2: 0.9013 - val_loss: 0.0286 - val_R2: 0.9574\n",
      "Epoch 459/5000\n",
      "1597/1597 [==============================] - 0s 305us/sample - loss: 0.0495 - R2: 0.9262 - val_loss: 0.0187 - val_R2: 0.9624\n",
      "Epoch 460/5000\n",
      "1597/1597 [==============================] - 0s 277us/sample - loss: 0.0585 - R2: 0.8426 - val_loss: 0.0279 - val_R2: 0.9264\n",
      "Epoch 461/5000\n",
      "1597/1597 [==============================] - 0s 277us/sample - loss: 0.0538 - R2: 0.8709 - val_loss: 0.0324 - val_R2: 0.9147\n",
      "Epoch 462/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.0525 - R2: 0.9039 - val_loss: 0.0207 - val_R2: 0.9613\n",
      "Epoch 463/5000\n",
      "1597/1597 [==============================] - 0s 299us/sample - loss: 0.0642 - R2: 0.8544 - val_loss: 0.0168 - val_R2: 0.9688\n",
      "Epoch 464/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.0496 - R2: 0.9051 - val_loss: 0.0251 - val_R2: 0.9632\n",
      "Epoch 465/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0538 - R2: 0.8994 - val_loss: 0.0202 - val_R2: 0.9468\n",
      "Epoch 466/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.0508 - R2: 0.8663 - val_loss: 0.0190 - val_R2: 0.9621\n",
      "Epoch 467/5000\n",
      "1597/1597 [==============================] - 0s 294us/sample - loss: 0.0596 - R2: 0.8617 - val_loss: 0.0223 - val_R2: 0.9700\n",
      "Epoch 468/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.0493 - R2: 0.8871 - val_loss: 0.0248 - val_R2: 0.9282\n",
      "Epoch 469/5000\n",
      "1597/1597 [==============================] - 0s 271us/sample - loss: 0.0517 - R2: 0.8939 - val_loss: 0.0182 - val_R2: 0.9781\n",
      "Epoch 470/5000\n",
      "1597/1597 [==============================] - 0s 267us/sample - loss: 0.0516 - R2: 0.8929 - val_loss: 0.0174 - val_R2: 0.9674\n",
      "Epoch 471/5000\n",
      "1597/1597 [==============================] - 0s 275us/sample - loss: 0.0573 - R2: 0.8902 - val_loss: 0.0211 - val_R2: 0.9441\n",
      "Epoch 472/5000\n",
      "1597/1597 [==============================] - 0s 279us/sample - loss: 0.0515 - R2: 0.8509 - val_loss: 0.0216 - val_R2: 0.9766\n",
      "Epoch 473/5000\n",
      "1597/1597 [==============================] - 0s 269us/sample - loss: 0.0489 - R2: 0.9193 - val_loss: 0.0187 - val_R2: 0.9494\n",
      "Epoch 474/5000\n",
      "1597/1597 [==============================] - 0s 263us/sample - loss: 0.0517 - R2: 0.8605 - val_loss: 0.0192 - val_R2: 0.9580\n",
      "Epoch 475/5000\n",
      "1597/1597 [==============================] - 0s 263us/sample - loss: 0.0567 - R2: 0.8562 - val_loss: 0.0289 - val_R2: 0.9010\n",
      "Epoch 476/5000\n",
      "1597/1597 [==============================] - 0s 285us/sample - loss: 0.0498 - R2: 0.8749 - val_loss: 0.0296 - val_R2: 0.9692\n",
      "Epoch 477/5000\n",
      "1597/1597 [==============================] - 0s 286us/sample - loss: 0.0485 - R2: 0.9377 - val_loss: 0.0220 - val_R2: 0.9578\n",
      "Epoch 478/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.0531 - R2: 0.9060 - val_loss: 0.0186 - val_R2: 0.9516\n",
      "Epoch 479/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.0484 - R2: 0.9075 - val_loss: 0.0317 - val_R2: 0.9455\n",
      "Epoch 480/5000\n",
      "1597/1597 [==============================] - 0s 295us/sample - loss: 0.0521 - R2: 0.9004 - val_loss: 0.0202 - val_R2: 0.9577\n",
      "Epoch 481/5000\n",
      "1597/1597 [==============================] - 0s 298us/sample - loss: 0.0488 - R2: 0.8850 - val_loss: 0.0199 - val_R2: 0.9697\n",
      "Epoch 482/5000\n",
      "1597/1597 [==============================] - 0s 273us/sample - loss: 0.0479 - R2: 0.8877 - val_loss: 0.0198 - val_R2: 0.9513\n",
      "Epoch 483/5000\n",
      "1597/1597 [==============================] - 0s 274us/sample - loss: 0.0499 - R2: 0.8842 - val_loss: 0.0290 - val_R2: 0.9553\n",
      "Epoch 484/5000\n",
      "1597/1597 [==============================] - 0s 280us/sample - loss: 0.0518 - R2: 0.9102 - val_loss: 0.0194 - val_R2: 0.9565\n",
      "Epoch 485/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.0498 - R2: 0.8848 - val_loss: 0.0195 - val_R2: 0.9728\n",
      "Epoch 486/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.0537 - R2: 0.8999 - val_loss: 0.0181 - val_R2: 0.9778\n",
      "Epoch 487/5000\n",
      "1597/1597 [==============================] - 0s 276us/sample - loss: 0.0454 - R2: 0.9024 - val_loss: 0.0264 - val_R2: 0.9684\n",
      "Epoch 488/5000\n",
      "1597/1597 [==============================] - 0s 278us/sample - loss: 0.0483 - R2: 0.8756 - val_loss: 0.0249 - val_R2: 0.9658\n",
      "Epoch 489/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.0537 - R2: 0.9074 - val_loss: 0.0253 - val_R2: 0.9674\n",
      "Epoch 490/5000\n",
      "1597/1597 [==============================] - 0s 277us/sample - loss: 0.0563 - R2: 0.8879 - val_loss: 0.0170 - val_R2: 0.9730\n",
      "Epoch 491/5000\n",
      "1597/1597 [==============================] - 0s 267us/sample - loss: 0.0477 - R2: 0.8852 - val_loss: 0.0160 - val_R2: 0.9751\n",
      "Epoch 492/5000\n",
      "1597/1597 [==============================] - 0s 273us/sample - loss: 0.0499 - R2: 0.8833 - val_loss: 0.0167 - val_R2: 0.9731\n",
      "Epoch 493/5000\n",
      "1597/1597 [==============================] - 0s 277us/sample - loss: 0.0502 - R2: 0.8885 - val_loss: 0.0164 - val_R2: 0.9774\n",
      "Epoch 494/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.0547 - R2: 0.8571 - val_loss: 0.0176 - val_R2: 0.9683\n",
      "Epoch 495/5000\n",
      "1597/1597 [==============================] - 0s 291us/sample - loss: 0.0493 - R2: 0.9152 - val_loss: 0.0214 - val_R2: 0.9750\n",
      "Epoch 496/5000\n",
      "1597/1597 [==============================] - 0s 268us/sample - loss: 0.0449 - R2: 0.8895 - val_loss: 0.0245 - val_R2: 0.9608\n",
      "Epoch 497/5000\n",
      "1597/1597 [==============================] - 0s 266us/sample - loss: 0.0516 - R2: 0.9016 - val_loss: 0.0174 - val_R2: 0.9776\n",
      "Epoch 498/5000\n",
      "1597/1597 [==============================] - 0s 280us/sample - loss: 0.0473 - R2: 0.8889 - val_loss: 0.0201 - val_R2: 0.9746\n",
      "Epoch 499/5000\n",
      "1597/1597 [==============================] - 0s 269us/sample - loss: 0.0438 - R2: 0.9278 - val_loss: 0.0181 - val_R2: 0.9680\n",
      "Epoch 500/5000\n",
      "1597/1597 [==============================] - 0s 274us/sample - loss: 0.0488 - R2: 0.8907 - val_loss: 0.0186 - val_R2: 0.9625\n",
      "Epoch 501/5000\n",
      "1597/1597 [==============================] - 0s 271us/sample - loss: 0.0493 - R2: 0.8847 - val_loss: 0.0213 - val_R2: 0.9541\n",
      "Epoch 502/5000\n",
      "1597/1597 [==============================] - 0s 280us/sample - loss: 0.0484 - R2: 0.8724 - val_loss: 0.0180 - val_R2: 0.9737\n",
      "Epoch 503/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.0499 - R2: 0.8980 - val_loss: 0.0262 - val_R2: 0.9120\n",
      "Epoch 504/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.0492 - R2: 0.9163 - val_loss: 0.0219 - val_R2: 0.9577\n",
      "Epoch 505/5000\n",
      "1597/1597 [==============================] - 0s 268us/sample - loss: 0.0499 - R2: 0.9218 - val_loss: 0.0261 - val_R2: 0.9383\n",
      "Epoch 506/5000\n",
      "1597/1597 [==============================] - 0s 304us/sample - loss: 0.0576 - R2: 0.8187 - val_loss: 0.0204 - val_R2: 0.9689\n",
      "Epoch 507/5000\n",
      "1597/1597 [==============================] - 0s 304us/sample - loss: 0.0431 - R2: 0.9081 - val_loss: 0.0190 - val_R2: 0.9772\n",
      "Epoch 508/5000\n",
      "1597/1597 [==============================] - 0s 306us/sample - loss: 0.0456 - R2: 0.9324 - val_loss: 0.0166 - val_R2: 0.9706\n",
      "Epoch 509/5000\n",
      "1597/1597 [==============================] - 0s 284us/sample - loss: 0.0463 - R2: 0.9286 - val_loss: 0.0169 - val_R2: 0.9551\n",
      "Epoch 510/5000\n",
      "1597/1597 [==============================] - 0s 283us/sample - loss: 0.0421 - R2: 0.8910 - val_loss: 0.0216 - val_R2: 0.9780\n",
      "Epoch 511/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.0505 - R2: 0.8652 - val_loss: 0.0166 - val_R2: 0.9646\n",
      "Epoch 512/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.0554 - R2: 0.9013 - val_loss: 0.0183 - val_R2: 0.9710\n",
      "Epoch 513/5000\n",
      "1597/1597 [==============================] - 0s 290us/sample - loss: 0.0443 - R2: 0.9109 - val_loss: 0.0168 - val_R2: 0.9757\n",
      "Epoch 514/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.0457 - R2: 0.9145 - val_loss: 0.0299 - val_R2: 0.9671\n",
      "Epoch 515/5000\n",
      "1597/1597 [==============================] - 0s 275us/sample - loss: 0.0513 - R2: 0.8823 - val_loss: 0.0210 - val_R2: 0.9434\n",
      "Epoch 516/5000\n",
      "1597/1597 [==============================] - 0s 274us/sample - loss: 0.0443 - R2: 0.9163 - val_loss: 0.0402 - val_R2: 0.9349\n",
      "Epoch 517/5000\n",
      "1597/1597 [==============================] - 0s 279us/sample - loss: 0.0476 - R2: 0.9247 - val_loss: 0.0149 - val_R2: 0.9803\n",
      "Epoch 518/5000\n",
      "1597/1597 [==============================] - 0s 276us/sample - loss: 0.0508 - R2: 0.8960 - val_loss: 0.0395 - val_R2: 0.9450\n",
      "Epoch 519/5000\n",
      "1597/1597 [==============================] - 0s 275us/sample - loss: 0.0451 - R2: 0.9115 - val_loss: 0.0324 - val_R2: 0.9409\n",
      "Epoch 520/5000\n",
      "1597/1597 [==============================] - 0s 292us/sample - loss: 0.0503 - R2: 0.8745 - val_loss: 0.0171 - val_R2: 0.9667\n",
      "Epoch 521/5000\n",
      "1597/1597 [==============================] - 0s 300us/sample - loss: 0.0449 - R2: 0.9043 - val_loss: 0.0137 - val_R2: 0.9833\n",
      "Epoch 522/5000\n",
      "1597/1597 [==============================] - 0s 296us/sample - loss: 0.0451 - R2: 0.9169 - val_loss: 0.0160 - val_R2: 0.9659\n",
      "Epoch 523/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.0470 - R2: 0.9190 - val_loss: 0.0176 - val_R2: 0.9695\n",
      "Epoch 524/5000\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.0467 - R2: 0.8939 - val_loss: 0.0195 - val_R2: 0.9565\n",
      "Epoch 525/5000\n",
      "1597/1597 [==============================] - 0s 280us/sample - loss: 0.0445 - R2: 0.9245 - val_loss: 0.0210 - val_R2: 0.9546\n",
      "Epoch 526/5000\n",
      "1597/1597 [==============================] - 0s 270us/sample - loss: 0.0438 - R2: 0.8938 - val_loss: 0.0191 - val_R2: 0.9657\n",
      "Epoch 527/5000\n",
      "1597/1597 [==============================] - 0s 276us/sample - loss: 0.0450 - R2: 0.8865 - val_loss: 0.0185 - val_R2: 0.9751\n",
      "Epoch 528/5000\n",
      "1597/1597 [==============================] - 0s 276us/sample - loss: 0.0400 - R2: 0.9181 - val_loss: 0.0436 - val_R2: 0.9366\n",
      "Epoch 529/5000\n",
      "1597/1597 [==============================] - 0s 283us/sample - loss: 0.0519 - R2: 0.8526 - val_loss: 0.0158 - val_R2: 0.9773\n",
      "Epoch 530/5000\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.0458 - R2: 0.9286 - val_loss: 0.0177 - val_R2: 0.9608\n",
      "Epoch 531/5000\n",
      "1597/1597 [==============================] - 0s 288us/sample - loss: 0.0469 - R2: 0.8901 - val_loss: 0.0228 - val_R2: 0.9181\n",
      "Epoch 532/5000\n",
      "1597/1597 [==============================] - 0s 279us/sample - loss: 0.0425 - R2: 0.9461 - val_loss: 0.0171 - val_R2: 0.9742\n",
      "Epoch 533/5000\n",
      "1392/1597 [=========================>....] - ETA: 0s - loss: 0.0370 - R2: 0.9374"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# R2 metric for tensorflow from https://jmlb.github.io/ml/2017/03/20/CoeffDetermination_CustomMetric4Keras/\n",
    "def R2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "# Where to save the figures and data files\n",
    "PROJECT_ROOT_DIR = \"Results\"\n",
    "FIGURE_ID = \"Results/FigureFiles\"\n",
    "DATA_ID = \"DataFiles/\"\n",
    "\n",
    "if not os.path.exists(PROJECT_ROOT_DIR):\n",
    "    os.mkdir(PROJECT_ROOT_DIR)\n",
    "\n",
    "if not os.path.exists(FIGURE_ID):\n",
    "    os.makedirs(FIGURE_ID)\n",
    "\n",
    "if not os.path.exists(DATA_ID):\n",
    "    os.makedirs(DATA_ID)\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(FIGURE_ID, fig_id)\n",
    "\n",
    "def data_path(dat_id):\n",
    "    return os.path.join(DATA_ID, dat_id)\n",
    "\n",
    "def save_fig(fig_id):\n",
    "    plt.savefig(image_path(fig_id) + \".png\", format='png')\n",
    "\n",
    "infile = open(data_path(\"MassEval2016.dat\"),'r')\n",
    "\n",
    "# Prevent TensorFlow from showing us deprecation warnings\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# Read the experimental data with Pandas\n",
    "Masses = pd.read_fwf(infile, usecols=(2,3,4,6,11),\n",
    "              names=('N', 'Z', 'A', 'Element', 'Ebinding'),\n",
    "              widths=(1,3,5,5,5,1,3,4,1,13,11,11,9,1,2,11,9,1,3,1,12,11,1),\n",
    "              header=39,\n",
    "              index_col=False)\n",
    "\n",
    "# Extrapolated values are indicated by '#' in place of the decimal place, so\n",
    "# the Ebinding column won't be numeric. Coerce to float and drop these entries.\n",
    "Masses['Ebinding'] = pd.to_numeric(Masses['Ebinding'], errors='coerce')\n",
    "Masses = Masses.dropna()\n",
    "# Convert from keV to MeV.\n",
    "Masses['Ebinding'] /= 1000\n",
    "\n",
    "# Group the DataFrame by nucleon number, A.\n",
    "#Masses = Masses.groupby('A')\n",
    "# Find the rows of the grouped DataFrame with the maximum binding energy.\n",
    "#Masses = Masses.apply(lambda t: t[t.Ebinding==t.Ebinding.max()])\n",
    "A = Masses['A']\n",
    "Z = Masses['Z']\n",
    "N = Masses['N']\n",
    "Element = Masses['Element']\n",
    "Energies = Masses['Ebinding']\n",
    "\n",
    "## All above comes from another notebook\n",
    "\n",
    "# Build input array\n",
    "xx = (Z.as_matrix()[:],N.as_matrix()[:])\n",
    "xx = np.asarray(xx)\n",
    "xx=xx.T\n",
    "yy = Energies\n",
    "\n",
    "# Get a test set for later\n",
    "x_train, x_test, y_train, y_test = train_test_split(xx,yy,test_size=0.2,random_state=42)\n",
    "\n",
    "# Scale input\n",
    "\n",
    "xs_train[:,0] = (x_train[:,0] - np.average(x_train[:,0])) / np.average(x_train[:,0])\n",
    "xs_test[:,0] = (x_test[:,0] - np.average(x_test[:,0])) / np.average(x_test[:,0])\n",
    "xs_train[:,1] = (x_train[:,1] - np.average(x_train[:,1])) / np.average(x_train[:,1])\n",
    "xs_test[:,1] = (x_test[:,1] - np.average(x_test[:,1])) / np.average(x_test[:,1])\n",
    "\n",
    "print('Training Features:\\n   Shape: {}\\n   Type: {}\\n'.format(xs_train.shape, xs_train.dtype))\n",
    "print('Training Targets:\\n   Shape: {}\\n   Type: {}\\n'.format(y_train.shape, y_train.dtype))\n",
    "print('Test Features:\\n   Shape: {}\\n   Type: {}\\n'.format(xs_test.shape, xs_test.dtype))\n",
    "print('Test Targets:\\n   Shape: {}\\n   Type: {}\\n'.format(y_test.shape, y_test.dtype))\n",
    "\n",
    "nodes = 50\n",
    "activation=\"relu\"\n",
    "model=tf.keras.Sequential() #Define the model object\n",
    "model.add(tf.keras.layers.Dense(nodes,input_shape=(2,),activation=activation)) #Add the hidden layer\n",
    "model.add(tf.keras.layers.Dense(nodes,input_shape=(nodes,),activation=activation)) #Add the hidden layer\n",
    "model.add(tf.keras.layers.Dense(nodes,input_shape=(nodes,),activation=activation)) #Add the hidden layer\n",
    "model.add(tf.keras.layers.Dense(nodes,input_shape=(nodes,),activation=activation)) #Add the hidden layer\n",
    "model.add(tf.keras.layers.Dense(1)) #Add the output layer\n",
    "model.compile(tf.keras.optimizers.Adam(lr=0.0001),loss=tf.keras.losses.MeanSquaredError(),metrics=[R2]) #Adam optimizer and mean squared error loss\n",
    "results=model.fit(xs_train,y_train,epochs=5000, batch_size=16, validation_split=0.2,verbose=1)\n",
    "\n",
    "history = results.history\n",
    "plt.plot(history[\"loss\"], label=\"training loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "\n",
    "# test loss calculation\n",
    "\n",
    "[test_loss,test_R2]=model.evaluate(xs_test, y_test, verbose=1)\n",
    "\n",
    "print('Test Loss: {:.04}'.format(test_loss))\n",
    "print('Test R2: {:.04}'.format(test_R2))\n",
    "\n",
    "en_out=model.predict(xs_test)\n",
    "\n",
    "# Shift back for plotting\n",
    "\n",
    "x_shift=xs_test\n",
    "x_shift[:,0]=xs_test[:,0]*np.average(x_test[:,0])+np.average(x_test[:,0])\n",
    "x_shift[:,1]=xs_test[:,1]*np.average(x_test[:,1])+np.average(x_test[:,1])\n",
    "\n",
    "a_sum=np.sum(x_shift,axis=1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(r'$A = N + Z$')\n",
    "ax.set_ylabel(r'$E_\\mathrm{bind}\\,/\\mathrm{MeV}$')\n",
    "ax.plot(Masses['A'], Masses['Ebinding'], 'ro',\n",
    "            label='Ame2016', alpha=0.7,c='b')\n",
    "ax.plot(a_sum, en_out,'ro',c='m')\n",
    "ax.legend()\n",
    "save_fig(\"Masses2016\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a little more\n",
    "\n",
    "If you want to run further epochs with the output model and a starting point, this cell should do it for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1597 samples, validate on 400 samples\n",
      "Epoch 1/20\n",
      "1597/1597 [==============================] - 0s 295us/sample - loss: 0.3868 - R2: 0.2396 - val_loss: 0.3661 - val_R2: 0.2544\n",
      "Epoch 2/20\n",
      "1597/1597 [==============================] - 0s 282us/sample - loss: 0.3740 - R2: 0.1859 - val_loss: 0.3499 - val_R2: 0.3032\n",
      "Epoch 3/20\n",
      "1597/1597 [==============================] - 0s 269us/sample - loss: 0.3555 - R2: 0.3553 - val_loss: 0.3358 - val_R2: 0.4143\n",
      "Epoch 4/20\n",
      "1597/1597 [==============================] - 0s 261us/sample - loss: 0.3408 - R2: 0.3357 - val_loss: 0.3205 - val_R2: 0.4763\n",
      "Epoch 5/20\n",
      "1597/1597 [==============================] - 0s 282us/sample - loss: 0.3261 - R2: 0.4467 - val_loss: 0.3073 - val_R2: 0.5435\n",
      "Epoch 6/20\n",
      "1597/1597 [==============================] - 0s 292us/sample - loss: 0.3125 - R2: 0.4289 - val_loss: 0.2950 - val_R2: 0.4642\n",
      "Epoch 7/20\n",
      "1597/1597 [==============================] - 0s 296us/sample - loss: 0.3009 - R2: 0.4515 - val_loss: 0.2839 - val_R2: 0.5463\n",
      "Epoch 8/20\n",
      "1597/1597 [==============================] - 0s 284us/sample - loss: 0.2905 - R2: 0.5400 - val_loss: 0.2738 - val_R2: 0.5626\n",
      "Epoch 9/20\n",
      "1597/1597 [==============================] - 0s 309us/sample - loss: 0.2818 - R2: 0.4999 - val_loss: 0.2668 - val_R2: 0.5915\n",
      "Epoch 10/20\n",
      "1597/1597 [==============================] - 0s 308us/sample - loss: 0.2748 - R2: 0.5547 - val_loss: 0.2561 - val_R2: 0.5326\n",
      "Epoch 11/20\n",
      "1597/1597 [==============================] - 0s 274us/sample - loss: 0.2636 - R2: 0.5534 - val_loss: 0.2496 - val_R2: 0.6002\n",
      "Epoch 12/20\n",
      "1597/1597 [==============================] - 0s 289us/sample - loss: 0.2542 - R2: 0.5369 - val_loss: 0.2477 - val_R2: 0.6651\n",
      "Epoch 13/20\n",
      "1597/1597 [==============================] - 0s 293us/sample - loss: 0.2516 - R2: 0.5993 - val_loss: 0.2348 - val_R2: 0.6122\n",
      "Epoch 14/20\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.2418 - R2: 0.5487 - val_loss: 0.2316 - val_R2: 0.6682\n",
      "Epoch 15/20\n",
      "1597/1597 [==============================] - 0s 275us/sample - loss: 0.2340 - R2: 0.6200 - val_loss: 0.2213 - val_R2: 0.6654\n",
      "Epoch 16/20\n",
      "1597/1597 [==============================] - 0s 273us/sample - loss: 0.2275 - R2: 0.6159 - val_loss: 0.2149 - val_R2: 0.6439\n",
      "Epoch 17/20\n",
      "1597/1597 [==============================] - 0s 287us/sample - loss: 0.2241 - R2: 0.6627 - val_loss: 0.2096 - val_R2: 0.6921\n",
      "Epoch 18/20\n",
      "1597/1597 [==============================] - 0s 300us/sample - loss: 0.2144 - R2: 0.6519 - val_loss: 0.2037 - val_R2: 0.7115\n",
      "Epoch 19/20\n",
      "1597/1597 [==============================] - 0s 270us/sample - loss: 0.2106 - R2: 0.6621 - val_loss: 0.1982 - val_R2: 0.7269\n",
      "Epoch 20/20\n",
      "1597/1597 [==============================] - 0s 295us/sample - loss: 0.2051 - R2: 0.6598 - val_loss: 0.1907 - val_R2: 0.6686\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 83us/sample - loss: 26753.3602 - R2: -158470.4844\n",
      "Test Loss: 2.675e+04\n",
      "Test R2: -1.585e+05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results=model.fit(xs_train,y_train,epochs=20, batch_size=16, validation_split=0.2,verbose=1)\n",
    "\n",
    "history = results.history\n",
    "plt.plot(history[\"loss\"], label=\"training loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "\n",
    "# test loss calculation\n",
    "\n",
    "[test_loss,test_R2]=model.evaluate(xs_test, y_test, verbose=1)\n",
    "\n",
    "print('Test Loss: {:.04}'.format(test_loss))\n",
    "print('Test R2: {:.04}'.format(test_R2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some predictions\n",
    "\n",
    "We can, in principle, hand the neural net a N,Z array, and predict binding energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict([8,8]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
